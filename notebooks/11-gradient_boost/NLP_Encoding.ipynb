{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1595581802527",
   "display_name": "Python 3.7.3 32-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center> Encoding </center></h1>\n",
    "\n",
    "*https://machinelearningmastery.com/why-one-hot-encode-data-in-machine-learning/*\n",
    "\n",
    "*https://machinelearningmastery.com/one-hot-encoding-for-categorical-data/*\n",
    "\n",
    "## *Written by Nathanael Hitch*\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often, machine learning data sets will require, or at least recommend, that you prepare your data in specific ways before fitting a machine learning model. Our main example is using one-hot encoding on categorical data.\n",
    "\n",
    "Categorical data are variables that contain label values, rather than numeric values, with the number of possible values often limited to a fixed set.\n",
    "\n",
    "- A \"pet\" variable with the values: \"dog\" and \"cat\".\n",
    "- A \"color\" variable with the values: \"red\", \"green\" and \"blue\".\n",
    "- A \"place\" variable with the values: \"first\", \"second\" and \"third\".\n",
    "\n",
    "Some algorithms can work with categorical data directly; a decision tree can learn directly from categorical data with no data transform required, depending on the specific implementation.<br>\n",
    "However, many machine learning algorithms cannot operate on label data directly, requiring all input variables and output variables to be numeric.\n",
    "\n",
    "This means that categorical data must be converted to a numerical form. Additionally, if the categorical variable is an output variable, you may also want to convert predictions by the model back into a categorical form in order to present them or use them in some application.\n",
    "\n",
    "### Convert from Categorical to numerical\n",
    "\n",
    "**1. Integer Encoding**\n",
    "\n",
    "Firstly, each unique category value is assigned an integer value. For example, \"red\" is 1, \"green\" is 2, and \"blue\" is 3. This is called a **label encoding**/**integer encoding** and is easily reversible.\n",
    "\n",
    "For some variables, this may be enough; the integer values have a natural ordered relationship between each other and machine learning algorithms may be able to understand and harness this relationship. The ordinal variables like the above \"place\" example would be a good example where a label encoding would be sufficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import asarray\n",
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[['red']\n ['green']\n ['blue']] \n\n[[2.]\n [1.]\n [0.]]\n"
    }
   ],
   "source": [
    "# define data\n",
    "data = asarray([['red'], ['green'], ['blue']])\n",
    "print(data, \"\\n\")\n",
    "\n",
    "# define ordinal encoding\n",
    "encoder = OrdinalEncoder()\n",
    "\n",
    "# transform data\n",
    "result = encoder.fit_transform(data)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. One-Hot Encoding**\n",
    "\n",
    "For categorical variables, where no such ordinal relationship exists, the integer encoding is not enough.<br>\n",
    "Using this encoding and allowing the model to assume a natural ordering between categories could result in poor performance or unexpected results (predictions halfway between categories).\n",
    "\n",
    "In this case, a one-hot encoding can be applied to the integer representation.\n",
    "- The integer encoded variable is removed and a new binary variable is added for each unique integer value.\n",
    "\n",
    "For the \"color\" variable example, there are 3 categories and therefore 3 binary variables are needed. A “1” value is placed in the binary variable for the color and \"0\" values for the other colors:\n",
    "\n",
    "red   = 1, 0, 0\n",
    "green = 0, 1, 0\n",
    "blue  = 0, 0, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[['red']\n ['green']\n ['blue']] \n\n[[0. 0. 1.]\n [0. 1. 0.]\n [1. 0. 0.]]\n"
    }
   ],
   "source": [
    "# define data\n",
    "data = asarray([['red'], ['green'], ['blue']])\n",
    "print(data, \"\\n\")\n",
    "\n",
    "# define one hot encoding\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "\n",
    "# transform data\n",
    "onehot = encoder.fit_transform(data)\n",
    "print(onehot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a dataset example (data directly from github):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Input (286, 9)\nOutput (286,)\n"
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "\n",
    "# define the location of the dataset\n",
    "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/breast-cancer.csv\"\n",
    "\n",
    "# load the dataset\n",
    "dataset = read_csv(url, header=None)\n",
    "\n",
    "# retrieve the array of data\n",
    "data = dataset.values\n",
    "\n",
    "# separate into input and output columns\n",
    "X = data[:, :-1].astype(str)\n",
    "y = data[:, -1].astype(str)\n",
    "\n",
    "# summarize\n",
    "print('Input', X.shape)\n",
    "print('Output', y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the labels (y), we can encode using the **Label Encoder**; this does the same as the other encoders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Input (286, 9)\n[[2. 2. 2. 0. 1. 2. 1. 2. 0.]\n [3. 0. 2. 0. 0. 0. 1. 0. 0.]\n [3. 0. 6. 0. 0. 1. 0. 1. 0.]\n [2. 2. 6. 0. 1. 2. 1. 1. 1.]\n [2. 2. 5. 4. 1. 1. 0. 4. 0.]]\nOutput (286,)\n[1 0 1 0 1]\n"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# ordinal encode input variables\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "X = ordinal_encoder.fit_transform(X)\n",
    "\n",
    "# ordinal encode target variable\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# summarize the transformed data\n",
    "print('Input', X.shape)\n",
    "print(X[:5, :])\n",
    "print('Output', y.shape)\n",
    "print(y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Logistic Regression Accuracy: 75.79\nLogistic Regression Precision: 91.67\nLogistic Regression Recall: 33.33\n"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "\n",
    "# ordinal encode input variables\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "ordinal_encoder.fit(X_train)\n",
    "\n",
    "X_train = ordinal_encoder.transform(X_train)\n",
    "X_test = ordinal_encoder.transform(X_test)\n",
    "\n",
    "# ordinal encode target variable\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "\n",
    "y_train = label_encoder.transform(y_train)\n",
    "y_test = label_encoder.transform(y_test)\n",
    "\n",
    "# define the model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# fit on the training set\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# predict on test set\n",
    "yhat = model.predict(X_test)\n",
    "\n",
    "# evaluate predictions\n",
    "print(\"Logistic Regression Accuracy: %.2f\" % (metrics.accuracy_score(y_test, yhat) * 100))\n",
    "print(\"Logistic Regression Precision: %.2f\" % (metrics.precision_score(y_test, yhat) * 100))\n",
    "print(\"Logistic Regression Recall: %.2f\" % (metrics.recall_score(y_test, yhat) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}