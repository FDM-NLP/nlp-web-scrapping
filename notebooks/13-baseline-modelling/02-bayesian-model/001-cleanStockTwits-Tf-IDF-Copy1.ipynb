{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report\n",
    "\n",
    "def get_metrics(y_test, y_predicted):  \n",
    "    # true positives / (true positives+false positives)\n",
    "    precision = precision_score(y_test, y_predicted, pos_label=None,\n",
    "                                    average='weighted')             \n",
    "    # true positives / (true positives + false negatives)\n",
    "    recall = recall_score(y_test, y_predicted, pos_label=None,\n",
    "                              average='weighted')\n",
    "    \n",
    "    # harmonic mean of precision and recall\n",
    "    f1 = f1_score(y_test, y_predicted, pos_label=None, average='weighted')\n",
    "    \n",
    "    # true positives + true negatives/ total\n",
    "    accuracy = accuracy_score(y_test, y_predicted)\n",
    "    return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This method creates classification integer\n",
    "Positive tweets : 1\n",
    "Neutral tweets : 0\n",
    "Negative tweets : -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#New column for classification labels, either 1 or 0\n",
    "def scoreCol(df, text_field):\n",
    "    scores = []\n",
    "    for x in df[text_field]:\n",
    "        if x == 'Bullish':\n",
    "            x = 1\n",
    "            \n",
    "        elif x == 'Bearish':\n",
    "            x = 0\n",
    "         \n",
    "        #else:\n",
    "            #print(':(')\n",
    "            \n",
    "        scores.append(x)        \n",
    "    df['scores'] = scores\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in dataset\n",
    "The first dataset is going to be the cleaned dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>message_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>securities</th>\n",
       "      <th>tweet text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>num_of_tokens</th>\n",
       "      <th>tokens_in_transformed_text</th>\n",
       "      <th>num_of_tokens_in_transformed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>babybounce</td>\n",
       "      <td>/babybounce/message/226382374</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>$BA travel going green bullish $CCL $RCL $NCLH...</td>\n",
       "      <td>09/07/2020</td>\n",
       "      <td>12:21:03</td>\n",
       "      <td>['$BA', '$CCL', '$RCL', '$NCLH', '$SPY']</td>\n",
       "      <td>travel going green bullish</td>\n",
       "      <td>['travel', 'going', 'green', 'bullish']</td>\n",
       "      <td>4</td>\n",
       "      <td>['travel', 'go', 'green', 'bullish']</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L1_Trading</td>\n",
       "      <td>/L1_Trading/message/226381562</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>$SPY let’s go mooning today</td>\n",
       "      <td>09/07/2020</td>\n",
       "      <td>12:21:03</td>\n",
       "      <td>['$SPY']</td>\n",
       "      <td>let’s go mooning today</td>\n",
       "      <td>['let', 'go', 'mooning', 'today']</td>\n",
       "      <td>4</td>\n",
       "      <td>['let', 'go', 'moon', 'today']</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Economist4401</td>\n",
       "      <td>/Economist4401/message/226381511</td>\n",
       "      <td>Bearish</td>\n",
       "      <td>$SPY $SPX $DJIA $DIA $QQQ Analysts on US stock...</td>\n",
       "      <td>09/07/2020</td>\n",
       "      <td>12:21:03</td>\n",
       "      <td>['$SPY', '$SPX', '$DJIA', '$DIA', '$QQQ']</td>\n",
       "      <td>Analysts on US stock markets: 1. On Monday, Bl...</td>\n",
       "      <td>['analysts', 'us', 'stock', 'markets', 'monday...</td>\n",
       "      <td>58</td>\n",
       "      <td>['analyst', 'us', 'stock', 'market', 'monday',...</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            user                        message_id sentiment  \\\n",
       "0     babybounce     /babybounce/message/226382374   Bullish   \n",
       "1     L1_Trading     /L1_Trading/message/226381562   Bullish   \n",
       "2  Economist4401  /Economist4401/message/226381511   Bearish   \n",
       "\n",
       "                                             content        date      time  \\\n",
       "0  $BA travel going green bullish $CCL $RCL $NCLH...  09/07/2020  12:21:03   \n",
       "1                        $SPY let’s go mooning today  09/07/2020  12:21:03   \n",
       "2  $SPY $SPX $DJIA $DIA $QQQ Analysts on US stock...  09/07/2020  12:21:03   \n",
       "\n",
       "                                  securities  \\\n",
       "0   ['$BA', '$CCL', '$RCL', '$NCLH', '$SPY']   \n",
       "1                                   ['$SPY']   \n",
       "2  ['$SPY', '$SPX', '$DJIA', '$DIA', '$QQQ']   \n",
       "\n",
       "                                          tweet text  \\\n",
       "0                         travel going green bullish   \n",
       "1                             let’s go mooning today   \n",
       "2  Analysts on US stock markets: 1. On Monday, Bl...   \n",
       "\n",
       "                                              tokens  num_of_tokens  \\\n",
       "0            ['travel', 'going', 'green', 'bullish']              4   \n",
       "1                  ['let', 'go', 'mooning', 'today']              4   \n",
       "2  ['analysts', 'us', 'stock', 'markets', 'monday...             58   \n",
       "\n",
       "                          tokens_in_transformed_text  \\\n",
       "0               ['travel', 'go', 'green', 'bullish']   \n",
       "1                     ['let', 'go', 'moon', 'today']   \n",
       "2  ['analyst', 'us', 'stock', 'market', 'monday',...   \n",
       "\n",
       "   num_of_tokens_in_transformed_text  \n",
       "0                                  4  \n",
       "1                                  4  \n",
       "2                                 37  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read data into dataframe\n",
    "#data = pd.read_csv(r'C:\\Users\\rsisl\\source\\repos\\NLP_Web_Scraping\\notebooks\\13-baseline-modelling\\cleanData.csv')\n",
    "data = pd.read_csv(r'..\\cleanData.csv')\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>message_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>securities</th>\n",
       "      <th>tweet text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>num_of_tokens</th>\n",
       "      <th>tokens_in_transformed_text</th>\n",
       "      <th>num_of_tokens_in_transformed_text</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>babybounce</td>\n",
       "      <td>/babybounce/message/226382374</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>$BA travel going green bullish $CCL $RCL $NCLH...</td>\n",
       "      <td>09/07/2020</td>\n",
       "      <td>12:21:03</td>\n",
       "      <td>['$BA', '$CCL', '$RCL', '$NCLH', '$SPY']</td>\n",
       "      <td>travel going green bullish</td>\n",
       "      <td>['travel', 'going', 'green', 'bullish']</td>\n",
       "      <td>4</td>\n",
       "      <td>['travel', 'go', 'green', 'bullish']</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L1_Trading</td>\n",
       "      <td>/L1_Trading/message/226381562</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>$SPY let’s go mooning today</td>\n",
       "      <td>09/07/2020</td>\n",
       "      <td>12:21:03</td>\n",
       "      <td>['$SPY']</td>\n",
       "      <td>let’s go mooning today</td>\n",
       "      <td>['let', 'go', 'mooning', 'today']</td>\n",
       "      <td>4</td>\n",
       "      <td>['let', 'go', 'moon', 'today']</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Economist4401</td>\n",
       "      <td>/Economist4401/message/226381511</td>\n",
       "      <td>Bearish</td>\n",
       "      <td>$SPY $SPX $DJIA $DIA $QQQ Analysts on US stock...</td>\n",
       "      <td>09/07/2020</td>\n",
       "      <td>12:21:03</td>\n",
       "      <td>['$SPY', '$SPX', '$DJIA', '$DIA', '$QQQ']</td>\n",
       "      <td>Analysts on US stock markets: 1. On Monday, Bl...</td>\n",
       "      <td>['analysts', 'us', 'stock', 'markets', 'monday...</td>\n",
       "      <td>58</td>\n",
       "      <td>['analyst', 'us', 'stock', 'market', 'monday',...</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            user                        message_id sentiment  \\\n",
       "0     babybounce     /babybounce/message/226382374   Bullish   \n",
       "1     L1_Trading     /L1_Trading/message/226381562   Bullish   \n",
       "2  Economist4401  /Economist4401/message/226381511   Bearish   \n",
       "\n",
       "                                             content        date      time  \\\n",
       "0  $BA travel going green bullish $CCL $RCL $NCLH...  09/07/2020  12:21:03   \n",
       "1                        $SPY let’s go mooning today  09/07/2020  12:21:03   \n",
       "2  $SPY $SPX $DJIA $DIA $QQQ Analysts on US stock...  09/07/2020  12:21:03   \n",
       "\n",
       "                                  securities  \\\n",
       "0   ['$BA', '$CCL', '$RCL', '$NCLH', '$SPY']   \n",
       "1                                   ['$SPY']   \n",
       "2  ['$SPY', '$SPX', '$DJIA', '$DIA', '$QQQ']   \n",
       "\n",
       "                                          tweet text  \\\n",
       "0                         travel going green bullish   \n",
       "1                             let’s go mooning today   \n",
       "2  Analysts on US stock markets: 1. On Monday, Bl...   \n",
       "\n",
       "                                              tokens  num_of_tokens  \\\n",
       "0            ['travel', 'going', 'green', 'bullish']              4   \n",
       "1                  ['let', 'go', 'mooning', 'today']              4   \n",
       "2  ['analysts', 'us', 'stock', 'markets', 'monday...             58   \n",
       "\n",
       "                          tokens_in_transformed_text  \\\n",
       "0               ['travel', 'go', 'green', 'bullish']   \n",
       "1                     ['let', 'go', 'moon', 'today']   \n",
       "2  ['analyst', 'us', 'stock', 'market', 'monday',...   \n",
       "\n",
       "   num_of_tokens_in_transformed_text  scores  \n",
       "0                                  4       1  \n",
       "1                                  4       1  \n",
       "2                                 37       0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Call classification label method\n",
    "data = scoreCol(data,'sentiment')\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get list of Tokens for each tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the list_corpus and the labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['travel going green bullish', 'let’s go mooning today', 'Analysts on US stock markets: 1. On Monday BlackRock downgraded US stocks from “overweight” to “neutral.” 2. Gary Shilling is very bearish on stock markets. He expects them to crash between 30% and 40% over the next year. 3. If Biden becomes president and raises taxes that President Trump lowered it could lead to upheaval and a possible crash in US stock markets. marketrealist.com/2020/07/w...', 'more China. China wants some of Australia lol🦘🦘🦘🦘', '“What Does The Institutional Ownership Tell Us About Greenlane Holdings? Many institutions measure their performance against an index that approximates the local market. So they usually pay more attention to companies that are included in major indices. We can see that Greenlane Holdings does have institutional investors; and they hold a good portion of the company’s stock. This implies the analysts working for those institutions have looked at the stock and they like it.” FB@risksavagemarket #watchthis simplywall.st/stocks/us/ret...']\n"
     ]
    }
   ],
   "source": [
    "# Create list_corpus\n",
    "token_list = data['tweet text'].tolist()\n",
    "list_corpus = []\n",
    "for tokens in token_list:\n",
    "    tokens = str(tokens) \n",
    "    tokens = tokens.replace(\"[\",\"\").replace(\"]\",\"\").replace(\"'\",\"\").replace(\",\",\"\")\n",
    "    list_corpus.append(tokens)\n",
    "print(list_corpus[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get labels\n",
    "list_labels = []\n",
    "for l in data['scores'].tolist():\n",
    "    label = int(l)\n",
    "    list_labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['travel going green bullish', 'let’s go mooning today', 'Analysts on US stock markets: 1. On Monday BlackRock downgraded US stocks from “overweight” to “neutral.” 2. Gary Shilling is very bearish on stock markets. He expects them to crash between 30% and 40% over the next year. 3. If Biden becomes president and raises taxes that President Trump lowered it could lead to upheaval and a possible crash in US stock markets. marketrealist.com/2020/07/w...', 'more China. China wants some of Australia lol🦘🦘🦘🦘', '“What Does The Institutional Ownership Tell Us About Greenlane Holdings? Many institutions measure their performance against an index that approximates the local market. So they usually pay more attention to companies that are included in major indices. We can see that Greenlane Holdings does have institutional investors; and they hold a good portion of the company’s stock. This implies the analysts working for those institutions have looked at the stock and they like it.” FB@risksavagemarket #watchthis simplywall.st/stocks/us/ret...']\n",
      "[1, 1, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "#Do a check...\n",
    "print(list_corpus[:5])\n",
    "print(list_labels[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bullish</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bullish</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bearish</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bearish</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bullish</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment  scores\n",
       "0   Bullish       1\n",
       "1   Bullish       1\n",
       "2   Bearish       0\n",
       "3   Bearish       0\n",
       "4   Bullish       1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['sentiment','scores']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create TF-IDF Vectorizer  - use the list corpus to create a CM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all review documents to a sparse matrix of token counts\n",
    "vectorizer = TfidfVectorizer() \n",
    "termDocumentMatrix = vectorizer.fit_transform(list_corpus) #this needs to include encoded tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24284, 19675)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "termDocumentMatrix.shape #add additional column - 'user_encoded'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the training dataset into two sections: \n",
    "x_train_tx, x_test_tx, y_train_tx, y_test_tx = train_test_split(termDocumentMatrix, list_labels, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19427, 4124)\n",
      "(4857, 4124)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted_counts_gb = gb.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_gb, precision_gb, recall_gb, f1_gb = get_metrics(y_test, y_predicted_counts_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_gb, precision_gb, recall_gb, f1_gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"data = cleaned Dataset: vectorizer = TfidfVectorizer, accuracy = %.3f, precision = %.3f, recall = %.3f, f1 = %.3f\" % (accuracy_gb, precision_gb, recall_gb, f1_gb))\n",
    "import pylab as pl\n",
    "import matplotlib.pyplot as plt\n",
    "print(\"data = cleaned Dataset: vectorizer = CountVectorizer, accuracy = %.3f, precision = %.3f, recall = %.3f, f1 = %.3f\" % (accuracy_gb, precision_gb, recall_gb, f1_gb))\n",
    "labels = [1,0]\n",
    "cm = metrics.confusion_matrix(y_test,y_predicted_counts_gb, labels)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(cm)\n",
    "plt.title('Confusion matrix of the classifier')\n",
    "fig.colorbar(cax)\n",
    "ax.set_xticklabels([''] + labels)\n",
    "ax.set_yticklabels([''] + labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label_encoder inside sklearn pre-propecessing (to incorporate users into x_train and x_test dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a Multinominal Classifier\n",
    "mnb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the model using the training sets\n",
    "mnb.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict the response for test dataset\n",
    "y_predicted_counts = mnb.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy, precision, recall, f1 = get_metrics(y_test, y_predicted_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"data = cleaned Dataset: vectorizer = TfidfVectorizer, accuracy = %.3f, precision = %.3f, recall = %.3f, f1 = %.3f\" % (accuracy, precision, recall, f1))\n",
    "import pylab as pl\n",
    "import matplotlib.pyplot as plt\n",
    "print(\"data = cleaned Dataset: vectorizer = CountVectorizer, accuracy = %.3f, precision = %.3f, recall = %.3f, f1 = %.3f\" % (accuracy, precision, recall, f1))\n",
    "labels = [1,0]\n",
    "cm = metrics.confusion_matrix(y_test,y_predicted_counts, labels)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(cm)\n",
    "plt.title('Confusion matrix of the classifier')\n",
    "fig.colorbar(cax)\n",
    "ax.set_xticklabels([''] + labels)\n",
    "ax.set_yticklabels([''] + labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create TF-IDF Vectorizer - use the 'user' column to create a CM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all review documents to a sparse matrix of token counts\n",
    "vectorizer = TfidfVectorizer() \n",
    "termDocumentMatrix_user = vectorizer.fit_transform(data['user'].tolist()) #this needs to include encoded tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the training dataset into two sections: \n",
    "x_train, x_test, y_train, y_test = train_test_split(termDocumentMatrix_user, list_labels, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_user = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_user.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted_counts_gb_user = gb_user.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_gb_user, precision_gb_user, recall_gb_user, f1_gb_user = get_metrics(y_test, y_predicted_counts_gb_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_gb_user, precision_gb_user, recall_gb_user, f1_gb_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"data = cleaned Dataset: vectorizer = TfidfVectorizer, accuracy = %.3f, precision = %.3f, recall = %.3f, f1 = %.3f\" % (accuracy_gb_user, precision_gb_user, recall_gb_user, f1_gb_user))\n",
    "import pylab as pl\n",
    "import matplotlib.pyplot as plt\n",
    "print(\"data = cleaned Dataset: vectorizer = CountVectorizer, accuracy = %.3f, precision = %.3f, recall = %.3f, f1 = %.3f\" % (accuracy_gb_user, precision_gb_user, recall_gb_user, f1_gb_user))\n",
    "labels = [1,0]\n",
    "cm = metrics.confusion_matrix(y_test, y_predicted_counts_gb_user, labels)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(cm)\n",
    "plt.title('Confusion matrix of the classifier')\n",
    "fig.colorbar(cax)\n",
    "ax.set_xticklabels([''] + labels)\n",
    "ax.set_yticklabels([''] + labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a Multinominal Classifier\n",
    "mnb_user = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the model using the training sets\n",
    "mnb_user.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict the response for test dataset\n",
    "y_predicted_counts_user = mnb_user.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_user, precision_user, recall_user, f1_user = get_metrics(y_test, y_predicted_counts_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"data = cleaned Dataset: vectorizer = TfidfVectorizer, accuracy = %.3f, precision = %.3f, recall = %.3f, f1 = %.3f\" % (accuracy_user, precision_user, recall_user, f1_user))\n",
    "import pylab as pl\n",
    "import matplotlib.pyplot as plt\n",
    "print(\"data = cleaned Dataset: vectorizer = CountVectorizer, accuracy = %.3f, precision = %.3f, recall = %.3f, f1 = %.3f\" % (accuracy_user, precision_user, recall_user, f1_user))\n",
    "labels = [1,0]\n",
    "cm = metrics.confusion_matrix(y_test,y_predicted_counts, labels)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(cm)\n",
    "plt.title('Confusion matrix of the classifier')\n",
    "fig.colorbar(cax)\n",
    "ax.set_xticklabels([''] + labels)\n",
    "ax.set_yticklabels([''] + labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Column combine 1st try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the training dataset into two sections: \n",
    "x_train_tx, x_test_tx, y_train_tx, y_test_tx = train_test_split(termDocumentMatrix, list_labels, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the training dataset into two sections: \n",
    "x_train, x_test, y_train, y_test = train_test_split(termDocumentMatrix_user, list_labels, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19427, 4124)\n",
      "(19427, 19675)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_train_tx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<19427x4124 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 19427 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<19427x19675 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 278027 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_tx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 1.42 GiB for an array with shape (19427, 19675) and data type int32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-b97fb33945fb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mx_train_user\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mx_test_user\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mx_train_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train_tx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mx_test_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test_tx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\sparse\\compressed.py\u001b[0m in \u001b[0;36mtoarray\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1023\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0morder\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1024\u001b[0m             \u001b[0morder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_swap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cf'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1025\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_toarray_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1026\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_contiguous\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_contiguous\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1027\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Output array must be C or F contiguous'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m_process_toarray_args\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1183\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1184\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1185\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 1.42 GiB for an array with shape (19427, 19675) and data type int32"
     ]
    }
   ],
   "source": [
    "x_train_user = pd.DataFrame(x_train.astype(int).toarray())\n",
    "x_test_user = pd.DataFrame(x_test.astype(int).toarray())\n",
    "x_train_text = pd.DataFrame(x_train_tx.astype(int).toarray())\n",
    "x_test_text = pd.DataFrame(x_test_tx.astype(int).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cvec' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-a06f29800ed3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m x_train_tx = pd.DataFrame(cvec.transform(x_train_tx).todense(),\n\u001b[0m\u001b[0;32m      2\u001b[0m                          columns=cvec.get_feature_names())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cvec' is not defined"
     ]
    }
   ],
   "source": [
    "x_train_tx = pd.DataFrame(cvec.transform(x_train_tx).todense(),\n",
    "                         columns=cvec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([x_train_tx,x_train], axis=1)\n",
    "test = pd.concat([x_test_tx, x_test], axis=1)\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "print(y_train)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24284 entries, 0 to 24283\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   user        24284 non-null  object\n",
      " 1   tweet text  24242 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 189.8+ KB\n"
     ]
    }
   ],
   "source": [
    "data[['user','tweet text']].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2nd Column combination attempt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>message_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>securities</th>\n",
       "      <th>tweet text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>num_of_tokens</th>\n",
       "      <th>tokens_in_transformed_text</th>\n",
       "      <th>num_of_tokens_in_transformed_text</th>\n",
       "      <th>scores</th>\n",
       "      <th>data_comb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>babybounce</td>\n",
       "      <td>/babybounce/message/226382374</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>$BA travel going green bullish $CCL $RCL $NCLH...</td>\n",
       "      <td>09/07/2020</td>\n",
       "      <td>12:21:03</td>\n",
       "      <td>['$BA', '$CCL', '$RCL', '$NCLH', '$SPY']</td>\n",
       "      <td>travel going green bullish</td>\n",
       "      <td>['travel', 'going', 'green', 'bullish']</td>\n",
       "      <td>4</td>\n",
       "      <td>['travel', 'go', 'green', 'bullish']</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>babybounce travel going green bullish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L1_Trading</td>\n",
       "      <td>/L1_Trading/message/226381562</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>$SPY let’s go mooning today</td>\n",
       "      <td>09/07/2020</td>\n",
       "      <td>12:21:03</td>\n",
       "      <td>['$SPY']</td>\n",
       "      <td>let’s go mooning today</td>\n",
       "      <td>['let', 'go', 'mooning', 'today']</td>\n",
       "      <td>4</td>\n",
       "      <td>['let', 'go', 'moon', 'today']</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>L1_Trading let’s go mooning today</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Economist4401</td>\n",
       "      <td>/Economist4401/message/226381511</td>\n",
       "      <td>Bearish</td>\n",
       "      <td>$SPY $SPX $DJIA $DIA $QQQ Analysts on US stock...</td>\n",
       "      <td>09/07/2020</td>\n",
       "      <td>12:21:03</td>\n",
       "      <td>['$SPY', '$SPX', '$DJIA', '$DIA', '$QQQ']</td>\n",
       "      <td>Analysts on US stock markets: 1. On Monday, Bl...</td>\n",
       "      <td>['analysts', 'us', 'stock', 'markets', 'monday...</td>\n",
       "      <td>58</td>\n",
       "      <td>['analyst', 'us', 'stock', 'market', 'monday',...</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>Economist4401 Analysts on US stock markets: 1....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            user                        message_id sentiment  \\\n",
       "0     babybounce     /babybounce/message/226382374   Bullish   \n",
       "1     L1_Trading     /L1_Trading/message/226381562   Bullish   \n",
       "2  Economist4401  /Economist4401/message/226381511   Bearish   \n",
       "\n",
       "                                             content        date      time  \\\n",
       "0  $BA travel going green bullish $CCL $RCL $NCLH...  09/07/2020  12:21:03   \n",
       "1                        $SPY let’s go mooning today  09/07/2020  12:21:03   \n",
       "2  $SPY $SPX $DJIA $DIA $QQQ Analysts on US stock...  09/07/2020  12:21:03   \n",
       "\n",
       "                                  securities  \\\n",
       "0   ['$BA', '$CCL', '$RCL', '$NCLH', '$SPY']   \n",
       "1                                   ['$SPY']   \n",
       "2  ['$SPY', '$SPX', '$DJIA', '$DIA', '$QQQ']   \n",
       "\n",
       "                                          tweet text  \\\n",
       "0                         travel going green bullish   \n",
       "1                             let’s go mooning today   \n",
       "2  Analysts on US stock markets: 1. On Monday, Bl...   \n",
       "\n",
       "                                              tokens  num_of_tokens  \\\n",
       "0            ['travel', 'going', 'green', 'bullish']              4   \n",
       "1                  ['let', 'go', 'mooning', 'today']              4   \n",
       "2  ['analysts', 'us', 'stock', 'markets', 'monday...             58   \n",
       "\n",
       "                          tokens_in_transformed_text  \\\n",
       "0               ['travel', 'go', 'green', 'bullish']   \n",
       "1                     ['let', 'go', 'moon', 'today']   \n",
       "2  ['analyst', 'us', 'stock', 'market', 'monday',...   \n",
       "\n",
       "   num_of_tokens_in_transformed_text  scores  \\\n",
       "0                                  4       1   \n",
       "1                                  4       1   \n",
       "2                                 37       0   \n",
       "\n",
       "                                           data_comb  \n",
       "0              babybounce travel going green bullish  \n",
       "1                  L1_Trading let’s go mooning today  \n",
       "2  Economist4401 Analysts on US stock markets: 1....  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#df = pd.DataFrame(data[['user','tweet text']]).astype(str)\n",
    "data['data_comb'] = data['user'].astype(str) + ' '+ data['tweet text'].astype(str)\n",
    "#df[data_comb] = df[['user','tweet text']].apply(lambda x: ''.join(x), axis=1)\n",
    "data.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['babybounce travel going green bullish', 'L1_Trading let’s go mooning today', 'Economist4401 Analysts on US stock markets: 1. On Monday BlackRock downgraded US stocks from “overweight” to “neutral.” 2. Gary Shilling is very bearish on stock markets. He expects them to crash between 30% and 40% over the next year. 3. If Biden becomes president and raises taxes that President Trump lowered it could lead to upheaval and a possible crash in US stock markets. marketrealist.com/2020/07/w...', 'OkieOkie more China. China wants some of Australia lol🦘🦘🦘🦘', 'risksavage_inthemarket “What Does The Institutional Ownership Tell Us About Greenlane Holdings? Many institutions measure their performance against an index that approximates the local market. So they usually pay more attention to companies that are included in major indices. We can see that Greenlane Holdings does have institutional investors; and they hold a good portion of the company’s stock. This implies the analysts working for those institutions have looked at the stock and they like it.” FB@risksavagemarket #watchthis simplywall.st/stocks/us/ret...']\n"
     ]
    }
   ],
   "source": [
    "# Create list_corpus\n",
    "token_list = data['data_comb'].tolist()\n",
    "list_corpus = []\n",
    "for tokens in token_list:\n",
    "    tokens = str(tokens) \n",
    "    tokens = tokens.replace(\"[\",\"\").replace(\"]\",\"\").replace(\"'\",\"\").replace(\",\",\"\")\n",
    "    list_corpus.append(tokens)\n",
    "print(list_corpus[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['babybounce travel going green bullish', 'L1_Trading let’s go mooning today', 'Economist4401 Analysts on US stock markets: 1. On Monday BlackRock downgraded US stocks from “overweight” to “neutral.” 2. Gary Shilling is very bearish on stock markets. He expects them to crash between 30% and 40% over the next year. 3. If Biden becomes president and raises taxes that President Trump lowered it could lead to upheaval and a possible crash in US stock markets. marketrealist.com/2020/07/w...', 'OkieOkie more China. China wants some of Australia lol🦘🦘🦘🦘', 'risksavage_inthemarket “What Does The Institutional Ownership Tell Us About Greenlane Holdings? Many institutions measure their performance against an index that approximates the local market. So they usually pay more attention to companies that are included in major indices. We can see that Greenlane Holdings does have institutional investors; and they hold a good portion of the company’s stock. This implies the analysts working for those institutions have looked at the stock and they like it.” FB@risksavagemarket #watchthis simplywall.st/stocks/us/ret...']\n",
      "[1, 1, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "#Do a check...\n",
    "print(list_corpus[:5])\n",
    "print(list_labels[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bullish</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bullish</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bearish</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bearish</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bullish</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment  scores\n",
       "0   Bullish       1\n",
       "1   Bullish       1\n",
       "2   Bearish       0\n",
       "3   Bearish       0\n",
       "4   Bullish       1"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['sentiment','scores']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all review documents to a sparse matrix of token counts\n",
    "vectorizer = TfidfVectorizer() \n",
    "termDocumentMatrix = vectorizer.fit_transform(list_corpus) #this needs to include encoded tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24284, 23636)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "termDocumentMatrix.shape #add additional column - 'user_encoded'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the training dataset into two sections: \n",
    "x_train_cb, x_test_cb, y_train_cb, y_test_cb = train_test_split(termDocumentMatrix, list_labels, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_cb = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier()"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_cb.fit(x_train_cb, y_train_cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted_counts_gb_cb = gb_cb.predict(x_test_cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_gb_cb, precision_gb_cb, recall_gb_cb, f1_gb_cb = get_metrics(y_test_cb, y_predicted_counts_gb_cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.72863907761993, 0.7565429373968696, 0.72863907761993, 0.7082596355856825)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_gb_cb, precision_gb_cb, recall_gb_cb, f1_gb_cb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data = cleaned Dataset: vectorizer = TfidfVectorizer, accuracy = 0.729, precision = 0.757, recall = 0.729, f1 = 0.708\n",
      "data = cleaned Dataset: vectorizer = CountVectorizer, accuracy = 0.729, precision = 0.757, recall = 0.729, f1 = 0.708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linda\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:68: FutureWarning: Pass labels=[1, 0] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2593  183]\n",
      " [1135  946]]\n"
     ]
    }
   ],
   "source": [
    "print(\"data = cleaned Dataset: vectorizer = TfidfVectorizer, accuracy = %.3f, precision = %.3f, recall = %.3f, f1 = %.3f\" % (accuracy_gb_cb, precision_gb_cb, recall_gb_cb, f1_gb_cb))\n",
    "import pylab as pl\n",
    "import matplotlib.pyplot as plt\n",
    "print(\"data = cleaned Dataset: vectorizer = CountVectorizer, accuracy = %.3f, precision = %.3f, recall = %.3f, f1 = %.3f\" % (accuracy_gb_cb, precision_gb_cb, recall_gb_cb, f1_gb_cb))\n",
    "labels = [1,0]\n",
    "cm = metrics.confusion_matrix(y_test_cb,y_predicted_counts_gb_cb, labels)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(cm)\n",
    "plt.title('Confusion matrix of the classifier')\n",
    "fig.colorbar(cax)\n",
    "ax.set_xticklabels([''] + labels)\n",
    "ax.set_yticklabels([''] + labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a Multinominal Classifier\n",
    "mnb_cb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the model using the training sets\n",
    "mnb_cb.fit(x_train_cb, y_train_cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict the response for test dataset\n",
    "y_predicted_counts_cb = mnb_cb.predict(x_test_cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_cb, precision_cb ,recall_cb, f1_cb = get_metrics(y_test_cb, y_predicted_counts_cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8567016676961087,\n",
       " 0.8586716755221726,\n",
       " 0.8567016676961087,\n",
       " 0.8551483231341568)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_cb, precision_cb ,recall_cb, f1_cb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data = cleaned Dataset: vectorizer = TfidfVectorizer, accuracy = 0.857, precision = 0.859, recall = 0.857, f1 = 0.855\n",
      "data = cleaned Dataset: vectorizer = CountVectorizer, accuracy = 0.857, precision = 0.859, recall = 0.857, f1 = 0.855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linda\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:68: FutureWarning: Pass labels=[1, 0] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2557  219]\n",
      " [ 477 1604]]\n"
     ]
    }
   ],
   "source": [
    "print(\"data = cleaned Dataset: vectorizer = TfidfVectorizer, accuracy = %.3f, precision = %.3f, recall = %.3f, f1 = %.3f\" % (accuracy_cb, precision_cb ,recall_cb, f1_cb))\n",
    "import pylab as pl\n",
    "import matplotlib.pyplot as plt\n",
    "print(\"data = cleaned Dataset: vectorizer = CountVectorizer, accuracy = %.3f, precision = %.3f, recall = %.3f, f1 = %.3f\" % (accuracy_cb, precision_cb ,recall_cb, f1_cb))\n",
    "labels = [1,0]\n",
    "cm = metrics.confusion_matrix(y_test_cb,y_predicted_counts_cb, labels)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(cm)\n",
    "plt.title('Confusion matrix of the classifier')\n",
    "fig.colorbar(cax)\n",
    "ax.set_xticklabels([''] + labels)\n",
    "ax.set_yticklabels([''] + labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross fold validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(vectorizer.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(termDocumentMatrix.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_pred = pd.DataFrame({'y_true':y_test, 'y_pred':y_predicted_counts})\n",
    "real_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = cross_val_score(mnb, x_train, y_train, scoring = 'accuracy', cv=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy archived: {0} %\".format( round(accuracy_score(real_pred['y_true'],real_pred['y_pred']), 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(real_pred['y_true'],real_pred['y_pred']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
