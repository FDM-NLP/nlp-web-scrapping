{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re, nltk\n",
    "from nltk.corpus import wordnet\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionaries for cleaning methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first dictionary includes contractions and their associated expansion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Contraction_Dictionary1 = {\n",
    "    \"ain/t\": \"is not\", \"aren/t\": \"are not\", \"can/t\": \"can not\", \"can/t/ve\": \"can not have\", \"cause\": \"because\", \"could/ve\": \"could have\",\n",
    "    \"couldn/t\": \"could not\", \"couldn/t/ve\": \"could not have\", \"didn/t\": \"did not\", \"doesn/t\": \"does not\", \"don/t\": \"do not\", \"hadn/t\": \"had not\",\n",
    "    \"hadn/t/ve\": \"had not have\", \"hasn/t\": \"has not\", \"haven/t\": \"have not\", \"he/d\": \"he would\", \"he/d/ve\": \"he would have\", \"he/ll\": \"he will\",\n",
    "    \"he/ll/ve\": \"he he will have\", \"he/s\": \"he is\", \"how/d\": \"how did\", \"how/d/y\": \"how do you\", \"how/ll\": \"how will\", \"how/s\": \"how is\",\n",
    "    \"I/d\": \"I would\", \"I/d/ve\": \"I would have\", \"I/ll\": \"I will\", \"I/ll/ve\": \"I will have\", \"I/m\": \"I am\", \"I/ve\": \"I have\", \"i/d\": \"i would\",\n",
    "    \"i/d/ve\": \"i would have\", \"i/ll\": \"i will\", \"i/ll/ve\": \"i will have\", \"i/m\": \"i am\", \"i/ve\": \"i have\", \"isn/t\": \"is not\", \"it/d\": \"it would\",\n",
    "    \"it/d/ve\": \"it would have\", \"it/ll\": \"it will\", \"it/ll/ve\": \"it will have\", \"it/s\": \"it is\", \"let/s\": \"let us\", \"ma/am\": \"madam\", \"mayn/t\": \"may not\",\n",
    "    \"might/ve\": \"might have\", \"mightn/t\": \"might not\", \"mightn/t/ve\": \"might not have\", \"must/ve\": \"must have\", \"mustn/t\": \"must not\", \"mustn/t/ve\": \"must not have\",\n",
    "    \"needn/t\": \"need not\", \"needn/t/ve\": \"need not have\", \"o/clock\": \"of the clock\", \"oughtn/t\": \"ought not\", \"oughtn/t/ve\": \"ought not have\", \"shan/t\": \"shall not\",\n",
    "    \"sha/n/t\": \"shall not\", \"shan/t/ve\": \"shall not have\", \"she/d\": \"she would\", \"she/d/ve\": \"she would have\", \"she/ll\": \"she will\", \"she/ll/ve\": \"she will have\",\n",
    "    \"she/s\": \"she is\", \"should/ve\": \"should have\", \"shouldn/t\": \"should not\", \"shouldn/t/ve\": \"should not have\", \"so/ve\": \"so have\", \"so/s\": \"so as\",\n",
    "    \"that/d\": \"that would\", \"that/d/ve\": \"that would have\", \"that/s\": \"that is\", \"there/d\": \"there would\", \"there/d/ve\": \"there would have\",\n",
    "    \"there/s\": \"there is\", \"they/d\": \"they would\", \"they/d/ve\": \"they would have\", \"they/ll\": \"they will\", \"they/ll/ve\": \"they will have\", \"they/re\": \"they are\",\n",
    "    \"they/ve\": \"they have\", \"to/ve\": \"to have\", \"wasn/t\": \"was not\", \"we/d\": \"we would\", \"we/d/ve\": \"we would have\", \"we/ll\": \"we will\", \"we/ll/ve\": \"we will have\", \n",
    "    \"we/re\": \"we are\", \"we/ve\": \"we have\", \"weren/t\": \"were not\", \"what/ll\": \"what will\", \"what/ll/ve\": \"what will have\",\"what/re\": \"what are\", \"what/s\": \"what is\", \n",
    "    \"what/ve\": \"what have\", \"when/s\": \"when is\", \"when/ve\": \"when have\", \"where/d\": \"where did\", \"where/s\": \"where is\", \"where/ve\": \"where have\",\n",
    "    \"who/ll\": \"who will\", \"who/ll/ve\": \"who will have\", \"who/s\": \"who is\", \"who/ve\": \"who have\", \"why/s\": \"why is\", \"why/ve\": \"why have\", \"will/ve\": \"will have\", \n",
    "    \"won/t\": \"will not\",\"won/t/ve\": \"will not have\", \"would/ve\": \"would have\", \"wouldn/t\": \"would not\", \"wouldn/t/ve\": \"would not have\", \"y/all\": \"you all\",\n",
    "    \"y/all/d\": \"you all would\", \"y/all/d/ve\": \"you all would have\", \"y/all/re\": \"you all are\", \"y/all/ve\": \"you all have\", \"you/d\": \"you would\",\n",
    "    \"you/d/ve\": \"you would have\", \"you/ll\": \"you will\", \"you/ll/ve\": \"you will have\", \"you/re\": \"you are\", \"you/ve\": \"you have\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This list contains an edited list of stopwords, with all negation words (e.g. 'no', 'never', 'not') excluded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words =['i','me','my','myself','we','our','ours','ourselves','you','your','yours','yourself',\n",
    "            'yourselves','he','him','his','himself','she','her','hers','herself','it','its','itself',\n",
    "            'they','them','their','theirs','themselves','what','which','who','whom','this','that',\n",
    "            'these','those','am','is','are','was','were','be','been','being','have','has','had',\n",
    "            'having','do','does','did','doing','a','an','the','and','but','if','or','because','as',\n",
    "            'until','while','of','at','by','for','with','about','against','between','into','through',\n",
    "            'during','before','after','above','below','to','from','up','down','in','out','on','off',\n",
    "            'over','under','again','further','then','once','here','there','when','where','why','how',\n",
    "            'all','any','both','each','few','more','most','other','some','such',\n",
    "            'only','own','same','so','than','too','very','can','will','just','should',\n",
    "            'now','uses','use','using','used','one','also']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This second list contains the nltk.wordnet labelling convertion for verbs, adjectives, nouns and adverbs. The purpose of this list is to only lemmatize words that are POS (part-of-speech) tagged with these labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PosList =[\"JJ\",\"JJR\",\"JJS\",\"NN\",\"NNS\",\"NNP\",\"NNPS\",\"RB\",\n",
    "          \"RBR\",\"RBS\",\"VB\",\"VBD\",\"VBG\",\"VBN\",\"VBP\",\"VBZ\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This second dictionary uses the POS tag label as a key to refer to the root/lemma of a word. The purpose of this is to identify words with these POS tags and lemmatize them to their root lemma. E.g. 'running' --> 'run'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "PosMapper = {\n",
    "\"JJ\": wordnet.ADJ,\n",
    "\"JJR\": wordnet.ADJ,\n",
    "\"JJS\": wordnet.ADJ,\n",
    "\"NN\": wordnet.NOUN,\n",
    "\"NNS\": wordnet.NOUN,\n",
    "\"NNP\": wordnet.NOUN,\n",
    "\"NNPS\": wordnet.NOUN,\n",
    "\"RB\": wordnet.ADV,\n",
    "\"RBR\": wordnet.ADV,\n",
    "\"RBS\": wordnet.ADV,\n",
    "\"VB\": wordnet.VERB,\n",
    "\"VBD\": wordnet.VERB,\n",
    "\"VBG\": wordnet.VERB,\n",
    "\"VBN\": wordnet.VERB,\n",
    "\"VBP\": wordnet.VERB,\n",
    "\"VBZ\": wordnet.VERB}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Innitialize the lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text normalization/standardization method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method normalizes the text into a coherent format for matching\n",
    "def standardize_text(df, text_field):\n",
    "    df[text_field] = df[text_field].str.lower() # Convert to lowercase\n",
    "    df[text_field] = df[text_field].str.replace('http','') # removing urls is useful to make vocabulary small as possible\n",
    "    df[text_field] = df[text_field].str.replace('com', '') # same as above.\n",
    "    df[text_field] = df[text_field].str.replace(r\"@\\S+\", \" \")\n",
    "    df[text_field] = df[text_field].str.replace(r\"[^A-Za-z0-9()$,!?@\\`\\\"\\'\\_\\n]\", \" \")\n",
    "    df[text_field] = df[text_field].str.replace(r\"@\", \"at\") #  replacing at sign for a word\n",
    "    df[text_field] = df[text_field].str.replace(\".\", \" \")\n",
    "    df[text_field] = df[text_field].str.replace(\",\", \" \")\n",
    "    df[text_field] = df[text_field].str.replace(\"-\", \" \")\n",
    "    df[text_field] = df[text_field].str.replace(\"(\", \" \")\n",
    "    df[text_field] = df[text_field].str.replace(\")\", \" \")\n",
    "    df[text_field] = df[text_field].str.replace('\"', \" \")\n",
    "    df[text_field] = df[text_field].str.replace(\"?\", \"\")\n",
    "    df[text_field] = df[text_field].str.replace(\"!\", \"\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contractions Expansion Prep\n",
    "In the data, contraction words such as wouldn't are noted as 'wouldn`t' ` which is a different character to the normal apostrophe. Therefore each instance is changed to a '/' in order to match contractions to the contraction dictionary equivalent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method strips the ` and changes is to / in order to match contractions.\n",
    "def contractionPrep(df, text_field):\n",
    "    df[text_field] = df[text_field].str.lstrip(' ')\n",
    "    df[text_field] = df[text_field].str.replace(\"'\", '/')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contraction Expansion Method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method expands all contractions to their original format\n",
    "def expand_contractions(text, contraction_mapping=Contraction_Dictionary1):\n",
    "    \n",
    "    contractions_pattern = re.compile('({})'.format('|'.join(contraction_mapping.keys())), \n",
    "                                      flags=re.IGNORECASE|re.DOTALL)\n",
    "    def expand_match(contraction):\n",
    "        match = contraction.group(0)\n",
    "        first_char = match[0]\n",
    "        expanded_contraction = contraction_mapping.get(match)                       \n",
    "        expanded_contraction = first_char+expanded_contraction[1:]\n",
    "        return expanded_contraction\n",
    "        \n",
    "    expanded_text = contractions_pattern.sub(expand_match, text)\n",
    "    expanded_text = re.sub(\"'\", \"\", expanded_text)\n",
    "    return expanded_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenisation Method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(x):\n",
    "    listOfTokens = []\n",
    "    for text in x:\n",
    "        text = str(text)\n",
    "        text = word_tokenize(text)\n",
    "        listOfTokens.append(text)\n",
    "    return listOfTokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Singleletter removal Method\n",
    "After an initial inspection into word frequency, single letter words were very frequent and didnt seem to contribute much semantic meaning the tweets, so were therefore removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def singleLetterRemoval(list_object):\n",
    "    listOfTokens = []\n",
    "    for tweet in list_object:\n",
    "        temp = []\n",
    "        for word in tweet:\n",
    "            if len(word) > 1:\n",
    "                temp.append(word)\n",
    "        listOfTokens.append(temp)\n",
    "    return listOfTokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number Removal Method\n",
    "Similarly to single letters, numbers dont contribute much meaning to the polarity of a tweet and so therefore removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numberRemoval(list_object):\n",
    "    listOfTokens = []\n",
    "    for tweet in list_object:\n",
    "        temp = []\n",
    "        for word in tweet:\n",
    "            if not word.isnumeric():\n",
    "                temp.append(word)\n",
    "        listOfTokens.append(temp)\n",
    "    return listOfTokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopword Removal Method\n",
    "Stopwords are the most frequent words in the corpus and only create noise for the classifier so were therefore removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopwordRemoval(list_object):\n",
    "    listOfTokens = []\n",
    "    for tweet in list_object:\n",
    "        temp = []\n",
    "        for word in tweet:\n",
    "            if not word in stop_words:\n",
    "                temp.append(word)\n",
    "        listOfTokens.append(temp)\n",
    "    return listOfTokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization Method\n",
    "Calls the Pos list and dictionary to return certain words into their root lemma format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemma(list_object):\n",
    "    tags = []\n",
    "    for words in list_object:\n",
    "        posTupples = nltk.pos_tag(words)\n",
    "        text = [lemmatizer.lemmatize(k[0], pos=PosMapper.get(k[1])) if k[1] in PosList else k[0] for k in posTupples]\n",
    "        tags.append(text)\n",
    "    return tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Append securities "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def appendSecurities(list_object):\n",
    "    listOfSecurities = []\n",
    "    for tweet in list_object:\n",
    "        temp = []\n",
    "        sentence = tweet.split()\n",
    "        for word in sentence:\n",
    "            if re.fullmatch(r'\\$[A-Z]{2,3}', word):\n",
    "                temp.append(word)\n",
    "        listOfSecurities.append(temp)\n",
    "    return listOfSecurities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove securities from content column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeSecurities(list_object):\n",
    "    sentence_without_dollar_signs = []\n",
    "    for tweet in list_object:\n",
    "        temp = []\n",
    "        sentence = tweet.split()\n",
    "        for word in sentence:\n",
    "            if not re.fullmatch(r'\\$[A-Z]{2,3}', word):\n",
    "                temp.append(word)\n",
    "        sentence_without_dollar_signs.append(' '.join(temp))\n",
    "    return sentence_without_dollar_signs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in dataset and clean it.\n",
    "In order to compare the raw dataset to the cleaned version, two datasets are created. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data to clean\n",
    "data = pd.read_csv(r'..\\NLP_Web_Scraping\\data\\raw\\scrapedtweets.csv')\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now remove securities from the dataset and add them to a new column\n",
    "\n",
    "Use remove securities function from earlier and apply to the content column in the dataset. Then output to a new column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>message_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>securities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>babybounce</td>\n",
       "      <td>/babybounce/message/226382374</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>$BA travel going green bullish $CCL $RCL $NCLH...</td>\n",
       "      <td>09/07/2020</td>\n",
       "      <td>12:21:03</td>\n",
       "      <td>[$BA, $CCL, $RCL, $SPY]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L1_Trading</td>\n",
       "      <td>/L1_Trading/message/226381562</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>$SPY let’s go mooning today</td>\n",
       "      <td>09/07/2020</td>\n",
       "      <td>12:21:03</td>\n",
       "      <td>[$SPY]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Economist4401</td>\n",
       "      <td>/Economist4401/message/226381511</td>\n",
       "      <td>Bearish</td>\n",
       "      <td>$SPY $SPX $DJIA $DIA $QQQ Analysts on US stock...</td>\n",
       "      <td>09/07/2020</td>\n",
       "      <td>12:21:03</td>\n",
       "      <td>[$SPY, $SPX, $DIA, $QQQ]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            user                        message_id sentiment  \\\n",
       "0     babybounce     /babybounce/message/226382374   Bullish   \n",
       "1     L1_Trading     /L1_Trading/message/226381562   Bullish   \n",
       "2  Economist4401  /Economist4401/message/226381511   Bearish   \n",
       "\n",
       "                                             content        date      time  \\\n",
       "0  $BA travel going green bullish $CCL $RCL $NCLH...  09/07/2020  12:21:03   \n",
       "1                        $SPY let’s go mooning today  09/07/2020  12:21:03   \n",
       "2  $SPY $SPX $DJIA $DIA $QQQ Analysts on US stock...  09/07/2020  12:21:03   \n",
       "\n",
       "                 securities  \n",
       "0   [$BA, $CCL, $RCL, $SPY]  \n",
       "1                    [$SPY]  \n",
       "2  [$SPY, $SPX, $DIA, $QQQ]  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#securities added to one column\n",
    "\n",
    "data['content'] = data['content'].astype('str')\n",
    "data['securities'] = appendSecurities(data['content'])\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>message_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>securities</th>\n",
       "      <th>tweet text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>babybounce</td>\n",
       "      <td>/babybounce/message/226382374</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>$BA travel going green bullish $CCL $RCL $NCLH...</td>\n",
       "      <td>09/07/2020</td>\n",
       "      <td>12:21:03</td>\n",
       "      <td>[$BA, $CCL, $RCL, $SPY]</td>\n",
       "      <td>travel going green bullish $NCLH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L1_Trading</td>\n",
       "      <td>/L1_Trading/message/226381562</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>$SPY let’s go mooning today</td>\n",
       "      <td>09/07/2020</td>\n",
       "      <td>12:21:03</td>\n",
       "      <td>[$SPY]</td>\n",
       "      <td>let’s go mooning today</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Economist4401</td>\n",
       "      <td>/Economist4401/message/226381511</td>\n",
       "      <td>Bearish</td>\n",
       "      <td>$SPY $SPX $DJIA $DIA $QQQ Analysts on US stock...</td>\n",
       "      <td>09/07/2020</td>\n",
       "      <td>12:21:03</td>\n",
       "      <td>[$SPY, $SPX, $DIA, $QQQ]</td>\n",
       "      <td>$DJIA Analysts on US stock markets: 1. On Mond...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            user                        message_id sentiment  \\\n",
       "0     babybounce     /babybounce/message/226382374   Bullish   \n",
       "1     L1_Trading     /L1_Trading/message/226381562   Bullish   \n",
       "2  Economist4401  /Economist4401/message/226381511   Bearish   \n",
       "\n",
       "                                             content        date      time  \\\n",
       "0  $BA travel going green bullish $CCL $RCL $NCLH...  09/07/2020  12:21:03   \n",
       "1                        $SPY let’s go mooning today  09/07/2020  12:21:03   \n",
       "2  $SPY $SPX $DJIA $DIA $QQQ Analysts on US stock...  09/07/2020  12:21:03   \n",
       "\n",
       "                 securities                                         tweet text  \n",
       "0   [$BA, $CCL, $RCL, $SPY]                   travel going green bullish $NCLH  \n",
       "1                    [$SPY]                             let’s go mooning today  \n",
       "2  [$SPY, $SPX, $DIA, $QQQ]  $DJIA Analysts on US stock markets: 1. On Mond...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use the content column to remove any securities from the tweet and add it to a new column\n",
    "data['tweet text'] = removeSecurities(data['content'])\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>message_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>securities</th>\n",
       "      <th>tweet text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>babybounce</td>\n",
       "      <td>/babybounce/message/226382374</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>$BA travel going green bullish $CCL $RCL $NCLH...</td>\n",
       "      <td>09/07/2020</td>\n",
       "      <td>12:21:03</td>\n",
       "      <td>[$BA, $CCL, $RCL, $SPY]</td>\n",
       "      <td>travel going green bullish $NCLH</td>\n",
       "      <td>travel going green bullish $NCLH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L1_Trading</td>\n",
       "      <td>/L1_Trading/message/226381562</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>$SPY let’s go mooning today</td>\n",
       "      <td>09/07/2020</td>\n",
       "      <td>12:21:03</td>\n",
       "      <td>[$SPY]</td>\n",
       "      <td>let’s go mooning today</td>\n",
       "      <td>let’s go mooning today</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Economist4401</td>\n",
       "      <td>/Economist4401/message/226381511</td>\n",
       "      <td>Bearish</td>\n",
       "      <td>$SPY $SPX $DJIA $DIA $QQQ Analysts on US stock...</td>\n",
       "      <td>09/07/2020</td>\n",
       "      <td>12:21:03</td>\n",
       "      <td>[$SPY, $SPX, $DIA, $QQQ]</td>\n",
       "      <td>$DJIA Analysts on US stock markets: 1. On Mond...</td>\n",
       "      <td>$DJIA Analysts on US stock markets: 1. On Mond...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OkieOkie</td>\n",
       "      <td>/OkieOkie/message/226381256</td>\n",
       "      <td>Bearish</td>\n",
       "      <td>$SPY more China. China wants some of Australia...</td>\n",
       "      <td>09/07/2020</td>\n",
       "      <td>12:21:03</td>\n",
       "      <td>[$SPY]</td>\n",
       "      <td>more China. China wants some of Australia lol🦘🦘🦘🦘</td>\n",
       "      <td>more China. China wants some of Australia lol🦘🦘🦘🦘</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>risksavage_inthemarket</td>\n",
       "      <td>/risksavage_inthemarket/message/226381105</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>$GNLN $CGC $SPY $KERN $PM “What Does The Insti...</td>\n",
       "      <td>09/07/2020</td>\n",
       "      <td>12:21:03</td>\n",
       "      <td>[$CGC, $SPY, $PM]</td>\n",
       "      <td>$GNLN $KERN “What Does The Institutional Owner...</td>\n",
       "      <td>$GNLN $KERN “What Does The Institutional Owner...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     user                                 message_id  \\\n",
       "0              babybounce              /babybounce/message/226382374   \n",
       "1              L1_Trading              /L1_Trading/message/226381562   \n",
       "2           Economist4401           /Economist4401/message/226381511   \n",
       "3                OkieOkie                /OkieOkie/message/226381256   \n",
       "4  risksavage_inthemarket  /risksavage_inthemarket/message/226381105   \n",
       "\n",
       "  sentiment                                            content        date  \\\n",
       "0   Bullish  $BA travel going green bullish $CCL $RCL $NCLH...  09/07/2020   \n",
       "1   Bullish                        $SPY let’s go mooning today  09/07/2020   \n",
       "2   Bearish  $SPY $SPX $DJIA $DIA $QQQ Analysts on US stock...  09/07/2020   \n",
       "3   Bearish  $SPY more China. China wants some of Australia...  09/07/2020   \n",
       "4   Bullish  $GNLN $CGC $SPY $KERN $PM “What Does The Insti...  09/07/2020   \n",
       "\n",
       "       time                securities  \\\n",
       "0  12:21:03   [$BA, $CCL, $RCL, $SPY]   \n",
       "1  12:21:03                    [$SPY]   \n",
       "2  12:21:03  [$SPY, $SPX, $DIA, $QQQ]   \n",
       "3  12:21:03                    [$SPY]   \n",
       "4  12:21:03         [$CGC, $SPY, $PM]   \n",
       "\n",
       "                                          tweet text  \\\n",
       "0                   travel going green bullish $NCLH   \n",
       "1                             let’s go mooning today   \n",
       "2  $DJIA Analysts on US stock markets: 1. On Mond...   \n",
       "3  more China. China wants some of Australia lol🦘🦘🦘🦘   \n",
       "4  $GNLN $KERN “What Does The Institutional Owner...   \n",
       "\n",
       "                                              tokens  \n",
       "0                   travel going green bullish $NCLH  \n",
       "1                             let’s go mooning today  \n",
       "2  $DJIA Analysts on US stock markets: 1. On Mond...  \n",
       "3  more China. China wants some of Australia lol🦘🦘🦘🦘  \n",
       "4  $GNLN $KERN “What Does The Institutional Owner...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['tokens'] = data['tweet text']\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>message_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>securities</th>\n",
       "      <th>tweet text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>babybounce</td>\n",
       "      <td>/babybounce/message/226382374</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>$BA travel going green bullish $CCL $RCL $NCLH...</td>\n",
       "      <td>09/07/2020</td>\n",
       "      <td>12:21:03</td>\n",
       "      <td>[$BA, $CCL, $RCL, $SPY]</td>\n",
       "      <td>travel going green bullish $NCLH</td>\n",
       "      <td>travel going green bullish $nclh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L1_Trading</td>\n",
       "      <td>/L1_Trading/message/226381562</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>$SPY let’s go mooning today</td>\n",
       "      <td>09/07/2020</td>\n",
       "      <td>12:21:03</td>\n",
       "      <td>[$SPY]</td>\n",
       "      <td>let’s go mooning today</td>\n",
       "      <td>let s go mooning today</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Economist4401</td>\n",
       "      <td>/Economist4401/message/226381511</td>\n",
       "      <td>Bearish</td>\n",
       "      <td>$SPY $SPX $DJIA $DIA $QQQ Analysts on US stock...</td>\n",
       "      <td>09/07/2020</td>\n",
       "      <td>12:21:03</td>\n",
       "      <td>[$SPY, $SPX, $DIA, $QQQ]</td>\n",
       "      <td>$DJIA Analysts on US stock markets: 1. On Mond...</td>\n",
       "      <td>$djia analysts on us stock markets  1  on mond...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OkieOkie</td>\n",
       "      <td>/OkieOkie/message/226381256</td>\n",
       "      <td>Bearish</td>\n",
       "      <td>$SPY more China. China wants some of Australia...</td>\n",
       "      <td>09/07/2020</td>\n",
       "      <td>12:21:03</td>\n",
       "      <td>[$SPY]</td>\n",
       "      <td>more China. China wants some of Australia lol🦘🦘🦘🦘</td>\n",
       "      <td>more china  china wants some of australia lol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>risksavage_inthemarket</td>\n",
       "      <td>/risksavage_inthemarket/message/226381105</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>$GNLN $CGC $SPY $KERN $PM “What Does The Insti...</td>\n",
       "      <td>09/07/2020</td>\n",
       "      <td>12:21:03</td>\n",
       "      <td>[$CGC, $SPY, $PM]</td>\n",
       "      <td>$GNLN $KERN “What Does The Institutional Owner...</td>\n",
       "      <td>$gnln $kern  what does the institutional owner...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     user                                 message_id  \\\n",
       "0              babybounce              /babybounce/message/226382374   \n",
       "1              L1_Trading              /L1_Trading/message/226381562   \n",
       "2           Economist4401           /Economist4401/message/226381511   \n",
       "3                OkieOkie                /OkieOkie/message/226381256   \n",
       "4  risksavage_inthemarket  /risksavage_inthemarket/message/226381105   \n",
       "\n",
       "  sentiment                                            content        date  \\\n",
       "0   Bullish  $BA travel going green bullish $CCL $RCL $NCLH...  09/07/2020   \n",
       "1   Bullish                        $SPY let’s go mooning today  09/07/2020   \n",
       "2   Bearish  $SPY $SPX $DJIA $DIA $QQQ Analysts on US stock...  09/07/2020   \n",
       "3   Bearish  $SPY more China. China wants some of Australia...  09/07/2020   \n",
       "4   Bullish  $GNLN $CGC $SPY $KERN $PM “What Does The Insti...  09/07/2020   \n",
       "\n",
       "       time                securities  \\\n",
       "0  12:21:03   [$BA, $CCL, $RCL, $SPY]   \n",
       "1  12:21:03                    [$SPY]   \n",
       "2  12:21:03  [$SPY, $SPX, $DIA, $QQQ]   \n",
       "3  12:21:03                    [$SPY]   \n",
       "4  12:21:03         [$CGC, $SPY, $PM]   \n",
       "\n",
       "                                          tweet text  \\\n",
       "0                   travel going green bullish $NCLH   \n",
       "1                             let’s go mooning today   \n",
       "2  $DJIA Analysts on US stock markets: 1. On Mond...   \n",
       "3  more China. China wants some of Australia lol🦘🦘🦘🦘   \n",
       "4  $GNLN $KERN “What Does The Institutional Owner...   \n",
       "\n",
       "                                              tokens  \n",
       "0                   travel going green bullish $nclh  \n",
       "1                             let s go mooning today  \n",
       "2  $djia analysts on us stock markets  1  on mond...  \n",
       "3  more china  china wants some of australia lol      \n",
       "4  $gnln $kern  what does the institutional owner...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardize Text\n",
    "\n",
    "data = standardize_text(data,'tokens')\n",
    "\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expand contractions\n",
    "Only the dataset that is being cleaned calls these methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data ready for Contraction Expansion\n",
    "data = contractionPrep(data,'tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>message_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>securities</th>\n",
       "      <th>tweet text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>babybounce</td>\n",
       "      <td>/babybounce/message/226382374</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>$BA travel going green bullish $CCL $RCL $NCLH...</td>\n",
       "      <td>09/07/2020</td>\n",
       "      <td>12:21:03</td>\n",
       "      <td>[$BA, $CCL, $RCL, $SPY]</td>\n",
       "      <td>travel going green bullish $NCLH</td>\n",
       "      <td>travel going green bullish $nclh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L1_Trading</td>\n",
       "      <td>/L1_Trading/message/226381562</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>$SPY let’s go mooning today</td>\n",
       "      <td>09/07/2020</td>\n",
       "      <td>12:21:03</td>\n",
       "      <td>[$SPY]</td>\n",
       "      <td>let’s go mooning today</td>\n",
       "      <td>let s go mooning today</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Economist4401</td>\n",
       "      <td>/Economist4401/message/226381511</td>\n",
       "      <td>Bearish</td>\n",
       "      <td>$SPY $SPX $DJIA $DIA $QQQ Analysts on US stock...</td>\n",
       "      <td>09/07/2020</td>\n",
       "      <td>12:21:03</td>\n",
       "      <td>[$SPY, $SPX, $DIA, $QQQ]</td>\n",
       "      <td>$DJIA Analysts on US stock markets: 1. On Mond...</td>\n",
       "      <td>$djia analysts on us stock markets  1  on mond...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OkieOkie</td>\n",
       "      <td>/OkieOkie/message/226381256</td>\n",
       "      <td>Bearish</td>\n",
       "      <td>$SPY more China. China wants some of Australia...</td>\n",
       "      <td>09/07/2020</td>\n",
       "      <td>12:21:03</td>\n",
       "      <td>[$SPY]</td>\n",
       "      <td>more China. China wants some of Australia lol🦘🦘🦘🦘</td>\n",
       "      <td>more china  china wants some of australia lol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>risksavage_inthemarket</td>\n",
       "      <td>/risksavage_inthemarket/message/226381105</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>$GNLN $CGC $SPY $KERN $PM “What Does The Insti...</td>\n",
       "      <td>09/07/2020</td>\n",
       "      <td>12:21:03</td>\n",
       "      <td>[$CGC, $SPY, $PM]</td>\n",
       "      <td>$GNLN $KERN “What Does The Institutional Owner...</td>\n",
       "      <td>$gnln $kern  what does the institutional owner...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     user                                 message_id  \\\n",
       "0              babybounce              /babybounce/message/226382374   \n",
       "1              L1_Trading              /L1_Trading/message/226381562   \n",
       "2           Economist4401           /Economist4401/message/226381511   \n",
       "3                OkieOkie                /OkieOkie/message/226381256   \n",
       "4  risksavage_inthemarket  /risksavage_inthemarket/message/226381105   \n",
       "\n",
       "  sentiment                                            content        date  \\\n",
       "0   Bullish  $BA travel going green bullish $CCL $RCL $NCLH...  09/07/2020   \n",
       "1   Bullish                        $SPY let’s go mooning today  09/07/2020   \n",
       "2   Bearish  $SPY $SPX $DJIA $DIA $QQQ Analysts on US stock...  09/07/2020   \n",
       "3   Bearish  $SPY more China. China wants some of Australia...  09/07/2020   \n",
       "4   Bullish  $GNLN $CGC $SPY $KERN $PM “What Does The Insti...  09/07/2020   \n",
       "\n",
       "       time                securities  \\\n",
       "0  12:21:03   [$BA, $CCL, $RCL, $SPY]   \n",
       "1  12:21:03                    [$SPY]   \n",
       "2  12:21:03  [$SPY, $SPX, $DIA, $QQQ]   \n",
       "3  12:21:03                    [$SPY]   \n",
       "4  12:21:03         [$CGC, $SPY, $PM]   \n",
       "\n",
       "                                          tweet text  \\\n",
       "0                   travel going green bullish $NCLH   \n",
       "1                             let’s go mooning today   \n",
       "2  $DJIA Analysts on US stock markets: 1. On Mond...   \n",
       "3  more China. China wants some of Australia lol🦘🦘🦘🦘   \n",
       "4  $GNLN $KERN “What Does The Institutional Owner...   \n",
       "\n",
       "                                              tokens  \n",
       "0                   travel going green bullish $nclh  \n",
       "1                             let s go mooning today  \n",
       "2  $djia analysts on us stock markets  1  on mond...  \n",
       "3  more china  china wants some of australia lol      \n",
       "4  $gnln $kern  what does the institutional owner...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Expand Contractions\n",
    "cleanedData = [expand_contractions(str(tweet)) for tweet in data['tokens']]\n",
    "data['tokens'] = cleanedData\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After inspecting the results there were still some square brackets remaining as part of some words so these needed to be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#strip remaining / from data\n",
    "data['tokens'] = data['tokens'].str.replace('/', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize Data\n",
    "This is applied to both datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize Data\n",
    "tweets = data['tokens'].tolist()\n",
    "tokenizedData = tokenizer(tweets)\n",
    "data['tokens'] = tokenizedData\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>message_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>securities</th>\n",
       "      <th>tweet text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>babybounce</td>\n",
       "      <td>/babybounce/message/226382374</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>$BA travel going green bullish $CCL $RCL $NCLH...</td>\n",
       "      <td>09/07/2020</td>\n",
       "      <td>12:21:03</td>\n",
       "      <td>[$BA, $CCL, $RCL, $SPY]</td>\n",
       "      <td>travel going green bullish $NCLH</td>\n",
       "      <td>[travel, going, green, bullish, $, nclh]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L1_Trading</td>\n",
       "      <td>/L1_Trading/message/226381562</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>$SPY let’s go mooning today</td>\n",
       "      <td>09/07/2020</td>\n",
       "      <td>12:21:03</td>\n",
       "      <td>[$SPY]</td>\n",
       "      <td>let’s go mooning today</td>\n",
       "      <td>[let, s, go, mooning, today]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         user                     message_id sentiment  \\\n",
       "0  babybounce  /babybounce/message/226382374   Bullish   \n",
       "1  L1_Trading  /L1_Trading/message/226381562   Bullish   \n",
       "\n",
       "                                             content        date      time  \\\n",
       "0  $BA travel going green bullish $CCL $RCL $NCLH...  09/07/2020  12:21:03   \n",
       "1                        $SPY let’s go mooning today  09/07/2020  12:21:03   \n",
       "\n",
       "                securities                        tweet text  \\\n",
       "0  [$BA, $CCL, $RCL, $SPY]  travel going green bullish $NCLH   \n",
       "1                   [$SPY]            let’s go mooning today   \n",
       "\n",
       "                                     tokens  \n",
       "0  [travel, going, green, bullish, $, nclh]  \n",
       "1              [let, s, go, mooning, today]  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call rest of cleaning methods on the dataset that is being cleaned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>message_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>securities</th>\n",
       "      <th>tweet text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>babybounce</td>\n",
       "      <td>/babybounce/message/226382374</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>$BA travel going green bullish $CCL $RCL $NCLH...</td>\n",
       "      <td>09/07/2020</td>\n",
       "      <td>12:21:03</td>\n",
       "      <td>[$BA, $CCL, $RCL, $SPY]</td>\n",
       "      <td>travel going green bullish $NCLH</td>\n",
       "      <td>[travel, going, green, bullish, nclh]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L1_Trading</td>\n",
       "      <td>/L1_Trading/message/226381562</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>$SPY let’s go mooning today</td>\n",
       "      <td>09/07/2020</td>\n",
       "      <td>12:21:03</td>\n",
       "      <td>[$SPY]</td>\n",
       "      <td>let’s go mooning today</td>\n",
       "      <td>[let, go, mooning, today]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Economist4401</td>\n",
       "      <td>/Economist4401/message/226381511</td>\n",
       "      <td>Bearish</td>\n",
       "      <td>$SPY $SPX $DJIA $DIA $QQQ Analysts on US stock...</td>\n",
       "      <td>09/07/2020</td>\n",
       "      <td>12:21:03</td>\n",
       "      <td>[$SPY, $SPX, $DIA, $QQQ]</td>\n",
       "      <td>$DJIA Analysts on US stock markets: 1. On Mond...</td>\n",
       "      <td>[djia, analysts, on, us, stock, markets, on, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OkieOkie</td>\n",
       "      <td>/OkieOkie/message/226381256</td>\n",
       "      <td>Bearish</td>\n",
       "      <td>$SPY more China. China wants some of Australia...</td>\n",
       "      <td>09/07/2020</td>\n",
       "      <td>12:21:03</td>\n",
       "      <td>[$SPY]</td>\n",
       "      <td>more China. China wants some of Australia lol🦘🦘🦘🦘</td>\n",
       "      <td>[more, china, china, wants, some, of, australi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            user                        message_id sentiment  \\\n",
       "0     babybounce     /babybounce/message/226382374   Bullish   \n",
       "1     L1_Trading     /L1_Trading/message/226381562   Bullish   \n",
       "2  Economist4401  /Economist4401/message/226381511   Bearish   \n",
       "3       OkieOkie       /OkieOkie/message/226381256   Bearish   \n",
       "\n",
       "                                             content        date      time  \\\n",
       "0  $BA travel going green bullish $CCL $RCL $NCLH...  09/07/2020  12:21:03   \n",
       "1                        $SPY let’s go mooning today  09/07/2020  12:21:03   \n",
       "2  $SPY $SPX $DJIA $DIA $QQQ Analysts on US stock...  09/07/2020  12:21:03   \n",
       "3  $SPY more China. China wants some of Australia...  09/07/2020  12:21:03   \n",
       "\n",
       "                 securities  \\\n",
       "0   [$BA, $CCL, $RCL, $SPY]   \n",
       "1                    [$SPY]   \n",
       "2  [$SPY, $SPX, $DIA, $QQQ]   \n",
       "3                    [$SPY]   \n",
       "\n",
       "                                          tweet text  \\\n",
       "0                   travel going green bullish $NCLH   \n",
       "1                             let’s go mooning today   \n",
       "2  $DJIA Analysts on US stock markets: 1. On Mond...   \n",
       "3  more China. China wants some of Australia lol🦘🦘🦘🦘   \n",
       "\n",
       "                                              tokens  \n",
       "0              [travel, going, green, bullish, nclh]  \n",
       "1                          [let, go, mooning, today]  \n",
       "2  [djia, analysts, on, us, stock, markets, on, m...  \n",
       "3  [more, china, china, wants, some, of, australi...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#single letter removal:\n",
    "\n",
    "tweetData = data['tokens'].tolist()\n",
    "slRemoved = singleLetterRemoval(tweetData)\n",
    "data['tokens'] = slRemoved\n",
    "data.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>message_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>securities</th>\n",
       "      <th>tweet text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>babybounce</td>\n",
       "      <td>/babybounce/message/226382374</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>$BA travel going green bullish $CCL $RCL $NCLH...</td>\n",
       "      <td>09/07/2020</td>\n",
       "      <td>12:21:03</td>\n",
       "      <td>[$BA, $CCL, $RCL, $SPY]</td>\n",
       "      <td>travel going green bullish $NCLH</td>\n",
       "      <td>[travel, going, green, bullish, nclh]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L1_Trading</td>\n",
       "      <td>/L1_Trading/message/226381562</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>$SPY let’s go mooning today</td>\n",
       "      <td>09/07/2020</td>\n",
       "      <td>12:21:03</td>\n",
       "      <td>[$SPY]</td>\n",
       "      <td>let’s go mooning today</td>\n",
       "      <td>[let, go, mooning, today]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Economist4401</td>\n",
       "      <td>/Economist4401/message/226381511</td>\n",
       "      <td>Bearish</td>\n",
       "      <td>$SPY $SPX $DJIA $DIA $QQQ Analysts on US stock...</td>\n",
       "      <td>09/07/2020</td>\n",
       "      <td>12:21:03</td>\n",
       "      <td>[$SPY, $SPX, $DIA, $QQQ]</td>\n",
       "      <td>$DJIA Analysts on US stock markets: 1. On Mond...</td>\n",
       "      <td>[djia, analysts, on, us, stock, markets, on, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OkieOkie</td>\n",
       "      <td>/OkieOkie/message/226381256</td>\n",
       "      <td>Bearish</td>\n",
       "      <td>$SPY more China. China wants some of Australia...</td>\n",
       "      <td>09/07/2020</td>\n",
       "      <td>12:21:03</td>\n",
       "      <td>[$SPY]</td>\n",
       "      <td>more China. China wants some of Australia lol🦘🦘🦘🦘</td>\n",
       "      <td>[more, china, china, wants, some, of, australi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            user                        message_id sentiment  \\\n",
       "0     babybounce     /babybounce/message/226382374   Bullish   \n",
       "1     L1_Trading     /L1_Trading/message/226381562   Bullish   \n",
       "2  Economist4401  /Economist4401/message/226381511   Bearish   \n",
       "3       OkieOkie       /OkieOkie/message/226381256   Bearish   \n",
       "\n",
       "                                             content        date      time  \\\n",
       "0  $BA travel going green bullish $CCL $RCL $NCLH...  09/07/2020  12:21:03   \n",
       "1                        $SPY let’s go mooning today  09/07/2020  12:21:03   \n",
       "2  $SPY $SPX $DJIA $DIA $QQQ Analysts on US stock...  09/07/2020  12:21:03   \n",
       "3  $SPY more China. China wants some of Australia...  09/07/2020  12:21:03   \n",
       "\n",
       "                 securities  \\\n",
       "0   [$BA, $CCL, $RCL, $SPY]   \n",
       "1                    [$SPY]   \n",
       "2  [$SPY, $SPX, $DIA, $QQQ]   \n",
       "3                    [$SPY]   \n",
       "\n",
       "                                          tweet text  \\\n",
       "0                   travel going green bullish $NCLH   \n",
       "1                             let’s go mooning today   \n",
       "2  $DJIA Analysts on US stock markets: 1. On Mond...   \n",
       "3  more China. China wants some of Australia lol🦘🦘🦘🦘   \n",
       "\n",
       "                                              tokens  \n",
       "0              [travel, going, green, bullish, nclh]  \n",
       "1                          [let, go, mooning, today]  \n",
       "2  [djia, analysts, on, us, stock, markets, on, m...  \n",
       "3  [more, china, china, wants, some, of, australi...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#number removal\n",
    "# tweetData = data['tweet text'].tolist()\n",
    "# nRemoved = numberRemoval(tweetData)\n",
    "# data['tweet text'] = nRemoved\n",
    "\n",
    "tweetData = data['tokens'].tolist()\n",
    "nRemoved = numberRemoval(tweetData)\n",
    "data['tokens'] = nRemoved\n",
    "data.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>message_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>securities</th>\n",
       "      <th>tweet text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>num_of_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>babybounce</td>\n",
       "      <td>/babybounce/message/226382374</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>$BA travel going green bullish $CCL $RCL $NCLH...</td>\n",
       "      <td>09/07/2020</td>\n",
       "      <td>12:21:03</td>\n",
       "      <td>[$BA, $CCL, $RCL, $SPY]</td>\n",
       "      <td>travel going green bullish $NCLH</td>\n",
       "      <td>[travel, going, green, bullish, nclh]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L1_Trading</td>\n",
       "      <td>/L1_Trading/message/226381562</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>$SPY let’s go mooning today</td>\n",
       "      <td>09/07/2020</td>\n",
       "      <td>12:21:03</td>\n",
       "      <td>[$SPY]</td>\n",
       "      <td>let’s go mooning today</td>\n",
       "      <td>[let, go, mooning, today]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Economist4401</td>\n",
       "      <td>/Economist4401/message/226381511</td>\n",
       "      <td>Bearish</td>\n",
       "      <td>$SPY $SPX $DJIA $DIA $QQQ Analysts on US stock...</td>\n",
       "      <td>09/07/2020</td>\n",
       "      <td>12:21:03</td>\n",
       "      <td>[$SPY, $SPX, $DIA, $QQQ]</td>\n",
       "      <td>$DJIA Analysts on US stock markets: 1. On Mond...</td>\n",
       "      <td>[djia, analysts, on, us, stock, markets, on, m...</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OkieOkie</td>\n",
       "      <td>/OkieOkie/message/226381256</td>\n",
       "      <td>Bearish</td>\n",
       "      <td>$SPY more China. China wants some of Australia...</td>\n",
       "      <td>09/07/2020</td>\n",
       "      <td>12:21:03</td>\n",
       "      <td>[$SPY]</td>\n",
       "      <td>more China. China wants some of Australia lol🦘🦘🦘🦘</td>\n",
       "      <td>[more, china, china, wants, some, of, australi...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>risksavage_inthemarket</td>\n",
       "      <td>/risksavage_inthemarket/message/226381105</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>$GNLN $CGC $SPY $KERN $PM “What Does The Insti...</td>\n",
       "      <td>09/07/2020</td>\n",
       "      <td>12:21:03</td>\n",
       "      <td>[$CGC, $SPY, $PM]</td>\n",
       "      <td>$GNLN $KERN “What Does The Institutional Owner...</td>\n",
       "      <td>[gnln, kern, what, does, the, institutional, o...</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HeyYouWhoMe</td>\n",
       "      <td>/HeyYouWhoMe/message/226381022</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>$SPY up or down today</td>\n",
       "      <td>09/07/2020</td>\n",
       "      <td>12:21:03</td>\n",
       "      <td>[$SPY]</td>\n",
       "      <td>up or down today</td>\n",
       "      <td>[up, or, down, today]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KaroleinTriedToTrade</td>\n",
       "      <td>/KaroleinTriedToTrade/message/226380585</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>$SPY I hope this goes up so high</td>\n",
       "      <td>09/07/2020</td>\n",
       "      <td>12:21:03</td>\n",
       "      <td>[$SPY]</td>\n",
       "      <td>I hope this goes up so high</td>\n",
       "      <td>[hope, this, goes, up, so, high]</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DannETrader</td>\n",
       "      <td>/DannETrader/message/226380472</td>\n",
       "      <td>Bearish</td>\n",
       "      <td>$SPY yesterday was last day of FED repo’s. It ...</td>\n",
       "      <td>09/07/2020</td>\n",
       "      <td>12:21:03</td>\n",
       "      <td>[$SPY]</td>\n",
       "      <td>yesterday was last day of FED repo’s. It isn’t...</td>\n",
       "      <td>[yesterday, was, last, day, of, fed, repo, it,...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>shoaibfatima</td>\n",
       "      <td>/shoaibfatima/message/226380359</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>$SPY get in before the pump starts</td>\n",
       "      <td>09/07/2020</td>\n",
       "      <td>12:21:03</td>\n",
       "      <td>[$SPY]</td>\n",
       "      <td>get in before the pump starts</td>\n",
       "      <td>[get, in, before, the, pump, starts]</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Burrrr_time</td>\n",
       "      <td>/Burrrr_time/message/226379857</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>$SPY fed buying stock !!! Ath</td>\n",
       "      <td>09/07/2020</td>\n",
       "      <td>12:21:03</td>\n",
       "      <td>[$SPY]</td>\n",
       "      <td>fed buying stock !!! Ath</td>\n",
       "      <td>[fed, buying, stock, ath]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     user                                 message_id  \\\n",
       "0              babybounce              /babybounce/message/226382374   \n",
       "1              L1_Trading              /L1_Trading/message/226381562   \n",
       "2           Economist4401           /Economist4401/message/226381511   \n",
       "3                OkieOkie                /OkieOkie/message/226381256   \n",
       "4  risksavage_inthemarket  /risksavage_inthemarket/message/226381105   \n",
       "5             HeyYouWhoMe             /HeyYouWhoMe/message/226381022   \n",
       "6    KaroleinTriedToTrade    /KaroleinTriedToTrade/message/226380585   \n",
       "7             DannETrader             /DannETrader/message/226380472   \n",
       "8            shoaibfatima            /shoaibfatima/message/226380359   \n",
       "9             Burrrr_time             /Burrrr_time/message/226379857   \n",
       "\n",
       "  sentiment                                            content        date  \\\n",
       "0   Bullish  $BA travel going green bullish $CCL $RCL $NCLH...  09/07/2020   \n",
       "1   Bullish                        $SPY let’s go mooning today  09/07/2020   \n",
       "2   Bearish  $SPY $SPX $DJIA $DIA $QQQ Analysts on US stock...  09/07/2020   \n",
       "3   Bearish  $SPY more China. China wants some of Australia...  09/07/2020   \n",
       "4   Bullish  $GNLN $CGC $SPY $KERN $PM “What Does The Insti...  09/07/2020   \n",
       "5   Bullish                              $SPY up or down today  09/07/2020   \n",
       "6   Bullish                   $SPY I hope this goes up so high  09/07/2020   \n",
       "7   Bearish  $SPY yesterday was last day of FED repo’s. It ...  09/07/2020   \n",
       "8   Bullish                 $SPY get in before the pump starts  09/07/2020   \n",
       "9   Bullish                      $SPY fed buying stock !!! Ath  09/07/2020   \n",
       "\n",
       "       time                securities  \\\n",
       "0  12:21:03   [$BA, $CCL, $RCL, $SPY]   \n",
       "1  12:21:03                    [$SPY]   \n",
       "2  12:21:03  [$SPY, $SPX, $DIA, $QQQ]   \n",
       "3  12:21:03                    [$SPY]   \n",
       "4  12:21:03         [$CGC, $SPY, $PM]   \n",
       "5  12:21:03                    [$SPY]   \n",
       "6  12:21:03                    [$SPY]   \n",
       "7  12:21:03                    [$SPY]   \n",
       "8  12:21:03                    [$SPY]   \n",
       "9  12:21:03                    [$SPY]   \n",
       "\n",
       "                                          tweet text  \\\n",
       "0                   travel going green bullish $NCLH   \n",
       "1                             let’s go mooning today   \n",
       "2  $DJIA Analysts on US stock markets: 1. On Mond...   \n",
       "3  more China. China wants some of Australia lol🦘🦘🦘🦘   \n",
       "4  $GNLN $KERN “What Does The Institutional Owner...   \n",
       "5                                   up or down today   \n",
       "6                        I hope this goes up so high   \n",
       "7  yesterday was last day of FED repo’s. It isn’t...   \n",
       "8                      get in before the pump starts   \n",
       "9                           fed buying stock !!! Ath   \n",
       "\n",
       "                                              tokens  num_of_tokens  \n",
       "0              [travel, going, green, bullish, nclh]              5  \n",
       "1                          [let, go, mooning, today]              4  \n",
       "2  [djia, analysts, on, us, stock, markets, on, m...             59  \n",
       "3  [more, china, china, wants, some, of, australi...              8  \n",
       "4  [gnln, kern, what, does, the, institutional, o...             82  \n",
       "5                              [up, or, down, today]              4  \n",
       "6                   [hope, this, goes, up, so, high]              6  \n",
       "7  [yesterday, was, last, day, of, fed, repo, it,...             12  \n",
       "8               [get, in, before, the, pump, starts]              6  \n",
       "9                          [fed, buying, stock, ath]              4  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data['num_of_tokens'] = data['tokens'].apply(lambda x: len(x))\n",
    "\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>message_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>securities</th>\n",
       "      <th>tweet text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>num_of_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>babybounce</td>\n",
       "      <td>/babybounce/message/226382374</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>$BA travel going green bullish $CCL $RCL $NCLH...</td>\n",
       "      <td>09/07/2020</td>\n",
       "      <td>12:21:03</td>\n",
       "      <td>[$BA, $CCL, $RCL, $SPY]</td>\n",
       "      <td>travel going green bullish $NCLH</td>\n",
       "      <td>[travel, going, green, bullish, nclh]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L1_Trading</td>\n",
       "      <td>/L1_Trading/message/226381562</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>$SPY let’s go mooning today</td>\n",
       "      <td>09/07/2020</td>\n",
       "      <td>12:21:03</td>\n",
       "      <td>[$SPY]</td>\n",
       "      <td>let’s go mooning today</td>\n",
       "      <td>[let, go, mooning, today]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Economist4401</td>\n",
       "      <td>/Economist4401/message/226381511</td>\n",
       "      <td>Bearish</td>\n",
       "      <td>$SPY $SPX $DJIA $DIA $QQQ Analysts on US stock...</td>\n",
       "      <td>09/07/2020</td>\n",
       "      <td>12:21:03</td>\n",
       "      <td>[$SPY, $SPX, $DIA, $QQQ]</td>\n",
       "      <td>$DJIA Analysts on US stock markets: 1. On Mond...</td>\n",
       "      <td>[djia, analysts, us, stock, markets, monday, b...</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OkieOkie</td>\n",
       "      <td>/OkieOkie/message/226381256</td>\n",
       "      <td>Bearish</td>\n",
       "      <td>$SPY more China. China wants some of Australia...</td>\n",
       "      <td>09/07/2020</td>\n",
       "      <td>12:21:03</td>\n",
       "      <td>[$SPY]</td>\n",
       "      <td>more China. China wants some of Australia lol🦘🦘🦘🦘</td>\n",
       "      <td>[china, china, wants, australia, lol]</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            user                        message_id sentiment  \\\n",
       "0     babybounce     /babybounce/message/226382374   Bullish   \n",
       "1     L1_Trading     /L1_Trading/message/226381562   Bullish   \n",
       "2  Economist4401  /Economist4401/message/226381511   Bearish   \n",
       "3       OkieOkie       /OkieOkie/message/226381256   Bearish   \n",
       "\n",
       "                                             content        date      time  \\\n",
       "0  $BA travel going green bullish $CCL $RCL $NCLH...  09/07/2020  12:21:03   \n",
       "1                        $SPY let’s go mooning today  09/07/2020  12:21:03   \n",
       "2  $SPY $SPX $DJIA $DIA $QQQ Analysts on US stock...  09/07/2020  12:21:03   \n",
       "3  $SPY more China. China wants some of Australia...  09/07/2020  12:21:03   \n",
       "\n",
       "                 securities  \\\n",
       "0   [$BA, $CCL, $RCL, $SPY]   \n",
       "1                    [$SPY]   \n",
       "2  [$SPY, $SPX, $DIA, $QQQ]   \n",
       "3                    [$SPY]   \n",
       "\n",
       "                                          tweet text  \\\n",
       "0                   travel going green bullish $NCLH   \n",
       "1                             let’s go mooning today   \n",
       "2  $DJIA Analysts on US stock markets: 1. On Mond...   \n",
       "3  more China. China wants some of Australia lol🦘🦘🦘🦘   \n",
       "\n",
       "                                              tokens  num_of_tokens  \n",
       "0              [travel, going, green, bullish, nclh]              5  \n",
       "1                          [let, go, mooning, today]              4  \n",
       "2  [djia, analysts, us, stock, markets, monday, b...             59  \n",
       "3              [china, china, wants, australia, lol]              8  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stopword removal\n",
    "tweetData = data['tokens'].tolist()\n",
    "noiseRemoved = stopwordRemoval(tweetData)\n",
    "data['tokens'] = noiseRemoved\n",
    "data.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatize the cleaned Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>message_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>securities</th>\n",
       "      <th>tweet text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>num_of_tokens</th>\n",
       "      <th>tokens_in_transformed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>babybounce</td>\n",
       "      <td>/babybounce/message/226382374</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>$BA travel going green bullish $CCL $RCL $NCLH...</td>\n",
       "      <td>09/07/2020</td>\n",
       "      <td>12:21:03</td>\n",
       "      <td>[$BA, $CCL, $RCL, $SPY]</td>\n",
       "      <td>travel going green bullish $NCLH</td>\n",
       "      <td>[travel, going, green, bullish, nclh]</td>\n",
       "      <td>5</td>\n",
       "      <td>[travel, go, green, bullish, nclh]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L1_Trading</td>\n",
       "      <td>/L1_Trading/message/226381562</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>$SPY let’s go mooning today</td>\n",
       "      <td>09/07/2020</td>\n",
       "      <td>12:21:03</td>\n",
       "      <td>[$SPY]</td>\n",
       "      <td>let’s go mooning today</td>\n",
       "      <td>[let, go, mooning, today]</td>\n",
       "      <td>4</td>\n",
       "      <td>[let, go, moon, today]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Economist4401</td>\n",
       "      <td>/Economist4401/message/226381511</td>\n",
       "      <td>Bearish</td>\n",
       "      <td>$SPY $SPX $DJIA $DIA $QQQ Analysts on US stock...</td>\n",
       "      <td>09/07/2020</td>\n",
       "      <td>12:21:03</td>\n",
       "      <td>[$SPY, $SPX, $DIA, $QQQ]</td>\n",
       "      <td>$DJIA Analysts on US stock markets: 1. On Mond...</td>\n",
       "      <td>[djia, analysts, us, stock, markets, monday, b...</td>\n",
       "      <td>59</td>\n",
       "      <td>[djia, analyst, us, stock, market, monday, bla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OkieOkie</td>\n",
       "      <td>/OkieOkie/message/226381256</td>\n",
       "      <td>Bearish</td>\n",
       "      <td>$SPY more China. China wants some of Australia...</td>\n",
       "      <td>09/07/2020</td>\n",
       "      <td>12:21:03</td>\n",
       "      <td>[$SPY]</td>\n",
       "      <td>more China. China wants some of Australia lol🦘🦘🦘🦘</td>\n",
       "      <td>[china, china, wants, australia, lol]</td>\n",
       "      <td>8</td>\n",
       "      <td>[china, china, want, australia, lol]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>risksavage_inthemarket</td>\n",
       "      <td>/risksavage_inthemarket/message/226381105</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>$GNLN $CGC $SPY $KERN $PM “What Does The Insti...</td>\n",
       "      <td>09/07/2020</td>\n",
       "      <td>12:21:03</td>\n",
       "      <td>[$CGC, $SPY, $PM]</td>\n",
       "      <td>$GNLN $KERN “What Does The Institutional Owner...</td>\n",
       "      <td>[gnln, kern, institutional, ownership, tell, u...</td>\n",
       "      <td>82</td>\n",
       "      <td>[gnln, kern, institutional, ownership, tell, u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     user                                 message_id  \\\n",
       "0              babybounce              /babybounce/message/226382374   \n",
       "1              L1_Trading              /L1_Trading/message/226381562   \n",
       "2           Economist4401           /Economist4401/message/226381511   \n",
       "3                OkieOkie                /OkieOkie/message/226381256   \n",
       "4  risksavage_inthemarket  /risksavage_inthemarket/message/226381105   \n",
       "\n",
       "  sentiment                                            content        date  \\\n",
       "0   Bullish  $BA travel going green bullish $CCL $RCL $NCLH...  09/07/2020   \n",
       "1   Bullish                        $SPY let’s go mooning today  09/07/2020   \n",
       "2   Bearish  $SPY $SPX $DJIA $DIA $QQQ Analysts on US stock...  09/07/2020   \n",
       "3   Bearish  $SPY more China. China wants some of Australia...  09/07/2020   \n",
       "4   Bullish  $GNLN $CGC $SPY $KERN $PM “What Does The Insti...  09/07/2020   \n",
       "\n",
       "       time                securities  \\\n",
       "0  12:21:03   [$BA, $CCL, $RCL, $SPY]   \n",
       "1  12:21:03                    [$SPY]   \n",
       "2  12:21:03  [$SPY, $SPX, $DIA, $QQQ]   \n",
       "3  12:21:03                    [$SPY]   \n",
       "4  12:21:03         [$CGC, $SPY, $PM]   \n",
       "\n",
       "                                          tweet text  \\\n",
       "0                   travel going green bullish $NCLH   \n",
       "1                             let’s go mooning today   \n",
       "2  $DJIA Analysts on US stock markets: 1. On Mond...   \n",
       "3  more China. China wants some of Australia lol🦘🦘🦘🦘   \n",
       "4  $GNLN $KERN “What Does The Institutional Owner...   \n",
       "\n",
       "                                              tokens  num_of_tokens  \\\n",
       "0              [travel, going, green, bullish, nclh]              5   \n",
       "1                          [let, go, mooning, today]              4   \n",
       "2  [djia, analysts, us, stock, markets, monday, b...             59   \n",
       "3              [china, china, wants, australia, lol]              8   \n",
       "4  [gnln, kern, institutional, ownership, tell, u...             82   \n",
       "\n",
       "                          tokens_in_transformed_text  \n",
       "0                 [travel, go, green, bullish, nclh]  \n",
       "1                             [let, go, moon, today]  \n",
       "2  [djia, analyst, us, stock, market, monday, bla...  \n",
       "3               [china, china, want, australia, lol]  \n",
       "4  [gnln, kern, institutional, ownership, tell, u...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "#Lemmatize Data\n",
    "tweetData = data['tokens'].tolist()\n",
    "lemmatizedData = lemma(tweetData)\n",
    "data['tokens_in_transformed_text'] = lemmatizedData\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See what the data looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>message_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>securities</th>\n",
       "      <th>tweet text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>num_of_tokens</th>\n",
       "      <th>tokens_in_transformed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>babybounce</td>\n",
       "      <td>/babybounce/message/226382374</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>$BA travel going green bullish $CCL $RCL $NCLH...</td>\n",
       "      <td>09/07/2020</td>\n",
       "      <td>12:21:03</td>\n",
       "      <td>[$BA, $CCL, $RCL, $SPY]</td>\n",
       "      <td>travel going green bullish $NCLH</td>\n",
       "      <td>[travel, going, green, bullish, nclh]</td>\n",
       "      <td>5</td>\n",
       "      <td>[travel, go, green, bullish, nclh]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L1_Trading</td>\n",
       "      <td>/L1_Trading/message/226381562</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>$SPY let’s go mooning today</td>\n",
       "      <td>09/07/2020</td>\n",
       "      <td>12:21:03</td>\n",
       "      <td>[$SPY]</td>\n",
       "      <td>let’s go mooning today</td>\n",
       "      <td>[let, go, mooning, today]</td>\n",
       "      <td>4</td>\n",
       "      <td>[let, go, moon, today]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Economist4401</td>\n",
       "      <td>/Economist4401/message/226381511</td>\n",
       "      <td>Bearish</td>\n",
       "      <td>$SPY $SPX $DJIA $DIA $QQQ Analysts on US stock...</td>\n",
       "      <td>09/07/2020</td>\n",
       "      <td>12:21:03</td>\n",
       "      <td>[$SPY, $SPX, $DIA, $QQQ]</td>\n",
       "      <td>$DJIA Analysts on US stock markets: 1. On Mond...</td>\n",
       "      <td>[djia, analysts, us, stock, markets, monday, b...</td>\n",
       "      <td>59</td>\n",
       "      <td>[djia, analyst, us, stock, market, monday, bla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OkieOkie</td>\n",
       "      <td>/OkieOkie/message/226381256</td>\n",
       "      <td>Bearish</td>\n",
       "      <td>$SPY more China. China wants some of Australia...</td>\n",
       "      <td>09/07/2020</td>\n",
       "      <td>12:21:03</td>\n",
       "      <td>[$SPY]</td>\n",
       "      <td>more China. China wants some of Australia lol🦘🦘🦘🦘</td>\n",
       "      <td>[china, china, wants, australia, lol]</td>\n",
       "      <td>8</td>\n",
       "      <td>[china, china, want, australia, lol]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>risksavage_inthemarket</td>\n",
       "      <td>/risksavage_inthemarket/message/226381105</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>$GNLN $CGC $SPY $KERN $PM “What Does The Insti...</td>\n",
       "      <td>09/07/2020</td>\n",
       "      <td>12:21:03</td>\n",
       "      <td>[$CGC, $SPY, $PM]</td>\n",
       "      <td>$GNLN $KERN “What Does The Institutional Owner...</td>\n",
       "      <td>[gnln, kern, institutional, ownership, tell, u...</td>\n",
       "      <td>82</td>\n",
       "      <td>[gnln, kern, institutional, ownership, tell, u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     user                                 message_id  \\\n",
       "0              babybounce              /babybounce/message/226382374   \n",
       "1              L1_Trading              /L1_Trading/message/226381562   \n",
       "2           Economist4401           /Economist4401/message/226381511   \n",
       "3                OkieOkie                /OkieOkie/message/226381256   \n",
       "4  risksavage_inthemarket  /risksavage_inthemarket/message/226381105   \n",
       "\n",
       "  sentiment                                            content        date  \\\n",
       "0   Bullish  $BA travel going green bullish $CCL $RCL $NCLH...  09/07/2020   \n",
       "1   Bullish                        $SPY let’s go mooning today  09/07/2020   \n",
       "2   Bearish  $SPY $SPX $DJIA $DIA $QQQ Analysts on US stock...  09/07/2020   \n",
       "3   Bearish  $SPY more China. China wants some of Australia...  09/07/2020   \n",
       "4   Bullish  $GNLN $CGC $SPY $KERN $PM “What Does The Insti...  09/07/2020   \n",
       "\n",
       "       time                securities  \\\n",
       "0  12:21:03   [$BA, $CCL, $RCL, $SPY]   \n",
       "1  12:21:03                    [$SPY]   \n",
       "2  12:21:03  [$SPY, $SPX, $DIA, $QQQ]   \n",
       "3  12:21:03                    [$SPY]   \n",
       "4  12:21:03         [$CGC, $SPY, $PM]   \n",
       "\n",
       "                                          tweet text  \\\n",
       "0                   travel going green bullish $NCLH   \n",
       "1                             let’s go mooning today   \n",
       "2  $DJIA Analysts on US stock markets: 1. On Mond...   \n",
       "3  more China. China wants some of Australia lol🦘🦘🦘🦘   \n",
       "4  $GNLN $KERN “What Does The Institutional Owner...   \n",
       "\n",
       "                                              tokens  num_of_tokens  \\\n",
       "0              [travel, going, green, bullish, nclh]              5   \n",
       "1                          [let, go, mooning, today]              4   \n",
       "2  [djia, analysts, us, stock, markets, monday, b...             59   \n",
       "3              [china, china, wants, australia, lol]              8   \n",
       "4  [gnln, kern, institutional, ownership, tell, u...             82   \n",
       "\n",
       "                          tokens_in_transformed_text  \n",
       "0                 [travel, go, green, bullish, nclh]  \n",
       "1                             [let, go, moon, today]  \n",
       "2  [djia, analyst, us, stock, market, monday, bla...  \n",
       "3               [china, china, want, australia, lol]  \n",
       "4  [gnln, kern, institutional, ownership, tell, u...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5) # cleanDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>message_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>securities</th>\n",
       "      <th>tweet text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>num_of_tokens</th>\n",
       "      <th>tokens_in_transformed_text</th>\n",
       "      <th>num_of_tokens_in_transformed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>babybounce</td>\n",
       "      <td>/babybounce/message/226382374</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>$BA travel going green bullish $CCL $RCL $NCLH...</td>\n",
       "      <td>09/07/2020</td>\n",
       "      <td>12:21:03</td>\n",
       "      <td>[$BA, $CCL, $RCL, $SPY]</td>\n",
       "      <td>travel going green bullish $NCLH</td>\n",
       "      <td>[travel, going, green, bullish, nclh]</td>\n",
       "      <td>5</td>\n",
       "      <td>[travel, go, green, bullish, nclh]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L1_Trading</td>\n",
       "      <td>/L1_Trading/message/226381562</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>$SPY let’s go mooning today</td>\n",
       "      <td>09/07/2020</td>\n",
       "      <td>12:21:03</td>\n",
       "      <td>[$SPY]</td>\n",
       "      <td>let’s go mooning today</td>\n",
       "      <td>[let, go, mooning, today]</td>\n",
       "      <td>4</td>\n",
       "      <td>[let, go, moon, today]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Economist4401</td>\n",
       "      <td>/Economist4401/message/226381511</td>\n",
       "      <td>Bearish</td>\n",
       "      <td>$SPY $SPX $DJIA $DIA $QQQ Analysts on US stock...</td>\n",
       "      <td>09/07/2020</td>\n",
       "      <td>12:21:03</td>\n",
       "      <td>[$SPY, $SPX, $DIA, $QQQ]</td>\n",
       "      <td>$DJIA Analysts on US stock markets: 1. On Mond...</td>\n",
       "      <td>[djia, analysts, us, stock, markets, monday, b...</td>\n",
       "      <td>59</td>\n",
       "      <td>[djia, analyst, us, stock, market, monday, bla...</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OkieOkie</td>\n",
       "      <td>/OkieOkie/message/226381256</td>\n",
       "      <td>Bearish</td>\n",
       "      <td>$SPY more China. China wants some of Australia...</td>\n",
       "      <td>09/07/2020</td>\n",
       "      <td>12:21:03</td>\n",
       "      <td>[$SPY]</td>\n",
       "      <td>more China. China wants some of Australia lol🦘🦘🦘🦘</td>\n",
       "      <td>[china, china, wants, australia, lol]</td>\n",
       "      <td>8</td>\n",
       "      <td>[china, china, want, australia, lol]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>risksavage_inthemarket</td>\n",
       "      <td>/risksavage_inthemarket/message/226381105</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>$GNLN $CGC $SPY $KERN $PM “What Does The Insti...</td>\n",
       "      <td>09/07/2020</td>\n",
       "      <td>12:21:03</td>\n",
       "      <td>[$CGC, $SPY, $PM]</td>\n",
       "      <td>$GNLN $KERN “What Does The Institutional Owner...</td>\n",
       "      <td>[gnln, kern, institutional, ownership, tell, u...</td>\n",
       "      <td>82</td>\n",
       "      <td>[gnln, kern, institutional, ownership, tell, u...</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HeyYouWhoMe</td>\n",
       "      <td>/HeyYouWhoMe/message/226381022</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>$SPY up or down today</td>\n",
       "      <td>09/07/2020</td>\n",
       "      <td>12:21:03</td>\n",
       "      <td>[$SPY]</td>\n",
       "      <td>up or down today</td>\n",
       "      <td>[today]</td>\n",
       "      <td>4</td>\n",
       "      <td>[today]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KaroleinTriedToTrade</td>\n",
       "      <td>/KaroleinTriedToTrade/message/226380585</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>$SPY I hope this goes up so high</td>\n",
       "      <td>09/07/2020</td>\n",
       "      <td>12:21:03</td>\n",
       "      <td>[$SPY]</td>\n",
       "      <td>I hope this goes up so high</td>\n",
       "      <td>[hope, goes, high]</td>\n",
       "      <td>6</td>\n",
       "      <td>[hope, go, high]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DannETrader</td>\n",
       "      <td>/DannETrader/message/226380472</td>\n",
       "      <td>Bearish</td>\n",
       "      <td>$SPY yesterday was last day of FED repo’s. It ...</td>\n",
       "      <td>09/07/2020</td>\n",
       "      <td>12:21:03</td>\n",
       "      <td>[$SPY]</td>\n",
       "      <td>yesterday was last day of FED repo’s. It isn’t...</td>\n",
       "      <td>[yesterday, last, day, fed, repo, isn, fed, an...</td>\n",
       "      <td>12</td>\n",
       "      <td>[yesterday, last, day, feed, repo, isn, feed, ...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>shoaibfatima</td>\n",
       "      <td>/shoaibfatima/message/226380359</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>$SPY get in before the pump starts</td>\n",
       "      <td>09/07/2020</td>\n",
       "      <td>12:21:03</td>\n",
       "      <td>[$SPY]</td>\n",
       "      <td>get in before the pump starts</td>\n",
       "      <td>[get, pump, starts]</td>\n",
       "      <td>6</td>\n",
       "      <td>[get, pump, start]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Burrrr_time</td>\n",
       "      <td>/Burrrr_time/message/226379857</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>$SPY fed buying stock !!! Ath</td>\n",
       "      <td>09/07/2020</td>\n",
       "      <td>12:21:03</td>\n",
       "      <td>[$SPY]</td>\n",
       "      <td>fed buying stock !!! Ath</td>\n",
       "      <td>[fed, buying, stock, ath]</td>\n",
       "      <td>4</td>\n",
       "      <td>[fed, buying, stock, ath]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     user                                 message_id  \\\n",
       "0              babybounce              /babybounce/message/226382374   \n",
       "1              L1_Trading              /L1_Trading/message/226381562   \n",
       "2           Economist4401           /Economist4401/message/226381511   \n",
       "3                OkieOkie                /OkieOkie/message/226381256   \n",
       "4  risksavage_inthemarket  /risksavage_inthemarket/message/226381105   \n",
       "5             HeyYouWhoMe             /HeyYouWhoMe/message/226381022   \n",
       "6    KaroleinTriedToTrade    /KaroleinTriedToTrade/message/226380585   \n",
       "7             DannETrader             /DannETrader/message/226380472   \n",
       "8            shoaibfatima            /shoaibfatima/message/226380359   \n",
       "9             Burrrr_time             /Burrrr_time/message/226379857   \n",
       "\n",
       "  sentiment                                            content        date  \\\n",
       "0   Bullish  $BA travel going green bullish $CCL $RCL $NCLH...  09/07/2020   \n",
       "1   Bullish                        $SPY let’s go mooning today  09/07/2020   \n",
       "2   Bearish  $SPY $SPX $DJIA $DIA $QQQ Analysts on US stock...  09/07/2020   \n",
       "3   Bearish  $SPY more China. China wants some of Australia...  09/07/2020   \n",
       "4   Bullish  $GNLN $CGC $SPY $KERN $PM “What Does The Insti...  09/07/2020   \n",
       "5   Bullish                              $SPY up or down today  09/07/2020   \n",
       "6   Bullish                   $SPY I hope this goes up so high  09/07/2020   \n",
       "7   Bearish  $SPY yesterday was last day of FED repo’s. It ...  09/07/2020   \n",
       "8   Bullish                 $SPY get in before the pump starts  09/07/2020   \n",
       "9   Bullish                      $SPY fed buying stock !!! Ath  09/07/2020   \n",
       "\n",
       "       time                securities  \\\n",
       "0  12:21:03   [$BA, $CCL, $RCL, $SPY]   \n",
       "1  12:21:03                    [$SPY]   \n",
       "2  12:21:03  [$SPY, $SPX, $DIA, $QQQ]   \n",
       "3  12:21:03                    [$SPY]   \n",
       "4  12:21:03         [$CGC, $SPY, $PM]   \n",
       "5  12:21:03                    [$SPY]   \n",
       "6  12:21:03                    [$SPY]   \n",
       "7  12:21:03                    [$SPY]   \n",
       "8  12:21:03                    [$SPY]   \n",
       "9  12:21:03                    [$SPY]   \n",
       "\n",
       "                                          tweet text  \\\n",
       "0                   travel going green bullish $NCLH   \n",
       "1                             let’s go mooning today   \n",
       "2  $DJIA Analysts on US stock markets: 1. On Mond...   \n",
       "3  more China. China wants some of Australia lol🦘🦘🦘🦘   \n",
       "4  $GNLN $KERN “What Does The Institutional Owner...   \n",
       "5                                   up or down today   \n",
       "6                        I hope this goes up so high   \n",
       "7  yesterday was last day of FED repo’s. It isn’t...   \n",
       "8                      get in before the pump starts   \n",
       "9                           fed buying stock !!! Ath   \n",
       "\n",
       "                                              tokens  num_of_tokens  \\\n",
       "0              [travel, going, green, bullish, nclh]              5   \n",
       "1                          [let, go, mooning, today]              4   \n",
       "2  [djia, analysts, us, stock, markets, monday, b...             59   \n",
       "3              [china, china, wants, australia, lol]              8   \n",
       "4  [gnln, kern, institutional, ownership, tell, u...             82   \n",
       "5                                            [today]              4   \n",
       "6                                 [hope, goes, high]              6   \n",
       "7  [yesterday, last, day, fed, repo, isn, fed, an...             12   \n",
       "8                                [get, pump, starts]              6   \n",
       "9                          [fed, buying, stock, ath]              4   \n",
       "\n",
       "                          tokens_in_transformed_text  \\\n",
       "0                 [travel, go, green, bullish, nclh]   \n",
       "1                             [let, go, moon, today]   \n",
       "2  [djia, analyst, us, stock, market, monday, bla...   \n",
       "3               [china, china, want, australia, lol]   \n",
       "4  [gnln, kern, institutional, ownership, tell, u...   \n",
       "5                                            [today]   \n",
       "6                                   [hope, go, high]   \n",
       "7  [yesterday, last, day, feed, repo, isn, feed, ...   \n",
       "8                                 [get, pump, start]   \n",
       "9                          [fed, buying, stock, ath]   \n",
       "\n",
       "   num_of_tokens_in_transformed_text  \n",
       "0                                  5  \n",
       "1                                  4  \n",
       "2                                 38  \n",
       "3                                  5  \n",
       "4                                 47  \n",
       "5                                  1  \n",
       "6                                  3  \n",
       "7                                  8  \n",
       "8                                  3  \n",
       "9                                  4  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data['num_of_tokens_in_transformed_text'] = data['tokens_in_transformed_text'].apply(lambda x: len(x))\n",
    "\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export dataframes to csv files: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '..\\\\NLP_Web_Scraping\\\\notebooks\\\\12-cleaning-raw-dataset\\\\Datasets\\\\cleanedData.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-3dfed0421e09>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Export to CSV\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'..\\NLP_Web_Scraping\\notebooks\\12-cleaning-raw-dataset\\Datasets\\cleanedData.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[0;32m   3202\u001b[0m             \u001b[0mdecimal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3203\u001b[0m         )\n\u001b[1;32m-> 3204\u001b[1;33m         \u001b[0mformatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3206\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    186\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 188\u001b[1;33m                 \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompression_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompression\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    189\u001b[0m             )\n\u001b[0;32m    190\u001b[0m             \u001b[0mclose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[0;32m    426\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 428\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    429\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    430\u001b[0m             \u001b[1;31m# No explicit encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '..\\\\NLP_Web_Scraping\\\\notebooks\\\\12-cleaning-raw-dataset\\\\Datasets\\\\cleanedData.csv'"
     ]
    }
   ],
   "source": [
    "#Export to CSV\n",
    "data.to_csv(r'..\\NLP_Web_Scraping\\notebooks\\12-cleaning-raw-dataset\\Datasets\\cleanedData.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
